{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Model training and evaluation\n",
    "In this lab we will train a multinomial classification model using the bottleneck features created in the previous part of the lab.\n",
    "\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/tlcl.png)\n",
    "\n",
    "We will start with training locally a simple logistic regression model to validate that the bottleneck features can deliver much better performance than raw pixel data. We will then use the Azure ML feature called `Automated ML` to find the optimal model and set of hyperparametrs.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/automated-machine-learning.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic regression model locally\n",
    "\n",
    "We will start by training a logistic regression model locally using the bottleneck features created in Lab 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to AML workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /Users/jarekk/repos/jakazmie/MTC_AzureAILabs/DataScienceTrack/01-aml-walkthrough/aml_config/config.json\n",
      "jkamllab\n",
      "jkamllab\n",
      "eastus2\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "import os\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download bottleneck features\n",
    "\n",
    "In the previous lab, the bottleneck features have been uploaded to the `bottleneck_features`folder in the default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'bottleneck_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "ds.download(target_path='.', prefix=data_folder, overwrite=True)\n",
    "!ls bottleneck_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train logistic regression using bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load features and labels into numpy arrays\n",
    "file_name = os.path.join(data_folder, 'aerial_bottleneck_resnet50.h5')\n",
    "with h5py.File(file_name, \"r\") as hfile:\n",
    "    features = np.array(hfile.get('features'))\n",
    "    labels = np.array(hfile.get('labels'))\n",
    " \n",
    "# Split the data into training and validation partitions   \n",
    "X_train, X_validation, y_train, y_validation = train_test_split(features, labels,\n",
    "                                                               test_size=0.1,\n",
    "                                                               shuffle=True,\n",
    "                                                               stratify=labels)\n",
    "    \n",
    "# Train logistics regresssion model\n",
    "reg = 0.1\n",
    "clf = LogisticRegression(\n",
    "        C=1.0/reg, \n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        random_state=1)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is: 0.9429864253393665\n"
     ]
    }
   ],
   "source": [
    "# Validate\n",
    "y_hat = clf.predict(X_validation)\n",
    "    \n",
    "# Calculate accuracy \n",
    "acc = np.average(y_hat == y_validation)\n",
    "print('Validation accuracy is:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aerial_lr.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "model_file='aerial_lr.pkl'\n",
    "\n",
    "joblib.dump(value=clf, filename=model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 832\n",
      "-rw-r--r--  1 jarekk  staff   99266 Nov  5 11:51 aerial_lr.pkl\n",
      "drwxr-xr-x  2 jarekk  staff      64 Nov  3 11:45 \u001b[34maml_config\u001b[m\u001b[m\n",
      "-rw-r--r--  1 jarekk  staff  159018 Nov  5 08:35 automl_errors.log\n",
      "drwxr-xr-x  3 jarekk  staff      96 Nov  3 10:56 \u001b[34mbottleneck_features\u001b[m\u001b[m\n",
      "-rw-r--r--  1 jarekk  staff   50370 Nov  5 09:05 model.pkl\n",
      "drwxr-xr-x  4 jarekk  staff     128 Nov  3 11:45 \u001b[34mscript\u001b[m\u001b[m\n",
      "-rw-r--r--  1 jarekk  staff   66088 Nov  5 11:50 train-evaluate.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model aerial_lr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azureml.core.model.Model at 0x1a41e21588>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "Model.register(ws, './aerial_lr.pkl', 'aerial_lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, the performance of the model trained on the bottleneck features is much better then the performance of the model trained on raw images. Our approach works. The next step is to find the most optimal classifier. We will accomplish that using the AML feature called `Automated ML`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated model selection\n",
    "\n",
    "Automated machine learning (automated ML) automatically picks an algorithm and hyperparameters that optimize a given  primary metric. The model can be downloaded to be further customized as well. There are several options that you can use to configure Automated ML experiments. In this section of the lab we will go through the steps to configure and run the `Automated ML` job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "\n",
    "We will create a new experiment to manage `Automated ML' runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'aerial-automatedML'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create  compute target\n",
    "\n",
    "Automated ML supports running concurrent experiments on Azure Batch AI clusters. This can significantly shorten the model selection and hyperparameter optimization process. \n",
    "\n",
    "**Note:** The creation of the Batch AI cluster can take over 10 minutes, please be patient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating\n",
      "succeeded.........\n",
      "BatchAI wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import BatchAiCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "batchai_cluster_name = \"batchaicls\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "for ct_name, ct in ws.compute_targets().items():\n",
    "    print(ct.name, ct.type)\n",
    "    if (ct.name == batchai_cluster_name and ct.type == 'BatchAI'):\n",
    "        found = True\n",
    "        print('Found existing compute target.')\n",
    "        bai_compute_target = ct\n",
    "        break\n",
    "        \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"STANDARD_DS2_V2\", \n",
    "                                                                autoscale_enabled = True,\n",
    "                                                                cluster_min_nodes = 1, \n",
    "                                                                cluster_max_nodes = 5)\n",
    "\n",
    "    # Create the cluster.\n",
    "    bai_compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
    "    \n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "    bai_compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "    \n",
    "     # For a more detailed view of current Batch AI cluster status, use the 'status' property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Get Data script\n",
    "\n",
    "If you are using a remote compute to run your Automated ML experiments, the data fetch must be wrapped in a separate python script that implements `get_data()` function. This script is run on the remote compute where the automated ML experiment is run. `get_data()` eliminates the need to fetch the data over the wire for each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/get_data.py\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_data():\n",
    "    # Load bottleneck features\n",
    "    data_folder = os.environ[\"AZUREML_DATAREFERENCE_workspacefilestore\"]\n",
    "    file_name = os.path.join(data_folder, 'aerial_bottleneck_resnet50.h5')\n",
    "    \n",
    "    print(\"Data folder:\", data_folder)\n",
    "    print(\"Bottleneck features file:\", file_name)\n",
    "    print(\"Data folder content:\", os.listdir(data_folder))\n",
    "    \n",
    "    with h5py.File(file_name, \"r\") as hfile:\n",
    "        features = np.array(hfile.get('features'))\n",
    "        labels = np.array(hfile.get('labels'))\n",
    "        \n",
    "    # Split the data into training and validation partitions   \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(features, labels,\n",
    "                                                               test_size=0.1,\n",
    "                                                               shuffle=True,\n",
    "                                                               stratify=labels)\n",
    "        \n",
    "\n",
    "    return {'X': X_train, 'y': y_train, 'X_valid': X_validation, 'y_valid': y_validation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure datastore and data reference\n",
    "\n",
    "The bottleneck files have been uploaded to the workspace's default datastore during the previous step. We will download the files onto the nodes of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default datastore for training data: \n",
      "workspacefilestore AzureFile jkamllab3089056971 azureml-filestore-83807581-3e38-45bd-9116-072c0b0f981d\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for training data: \")\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                   path_on_datastore='bottleneck_features', \n",
    "                   path_on_compute='bottleneck_features',\n",
    "                   mode='download', # download files from datastore to compute target\n",
    "                   overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Conda run configuration\n",
    "\n",
    "We will run `Automated ML` jobs in a custom docker image that will include dependencies required by `get_data()` script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# create a new RunConfig object\n",
    "run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Azure Batch AI cluster for Automated ML jobs require docker.\n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# Set compute target to BAI cluster\n",
    "run_config.target = bai_compute_target.name\n",
    "\n",
    "# Set data references\n",
    "run_config.data_references = {ds.name: dr}\n",
    "\n",
    "# specify packages required by get_data\n",
    "run_config.environment.python.conda_dependencies = \\\n",
    "   CondaDependencies.create(conda_packages=['h5py'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Automated ML run.\n",
    "\n",
    "Automated ML runs can be controlled using a number of configuration parameters. \n",
    "\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|classification or regression|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Classification supports the following primary metrics <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>balanced_accuracy</i><br><i>average_precision_score_weighted</i><br><i>precision_score_weighted</i>|\n",
    "|**max_time_sec**|Time limit in seconds for each iteration|\n",
    "|**iterations**|Number of iterations. In each iteration Auto ML trains a specific pipeline with the data|\n",
    "|**n_cross_validations**|Number of cross validation splits|\n",
    "|**concurrent_iterations**|Max number of iterations that would be executed in parallel. |\n",
    "|**preprocess**| *True/False* <br>Setting this to *True* enables Auto ML to perform preprocessing <br>on the input to handle *missing data*, and perform some common *feature extraction*|\n",
    "|**max_cores_per_iteration**| Indicates how many cores on the compute target would be used to train a single pipeline.<br> Default is *1*, you can set it to *-1* to use all cores|\n",
    "|**exit_score**|*double* value indicating the target for *primary_metric*. <br>Once the target is surpassed the run terminates.|\n",
    "|**blacklist_algos**|*List* of *strings* indicating machine learning algorithms for AutoML to avoid in this run.<br><br> Allowed values for **Classification**<br><i>LogisticRegression</i><br><i>SGDClassifierWrapper</i><br><i>NBWrapper</i><br><i>BernoulliNB</i><br><i>SVCWrapper</i><br><i>LinearSVMWrapper</i><br><i>KNeighborsClassifier</i><br><i>GradientBoostingClassifier</i><br><i>DecisionTreeClassifier</i><br><i>RandomForestClassifier</i><br><i>ExtraTreesClassifier</i><br><i>LightGBMClassifier</i><br><br>Allowed values for **Regression**<br><i>ElasticNet<i><br><i>GradientBoostingRegressor<i><br><i>DecisionTreeRegressor<i><br><i>KNeighborsRegressor<i><br><i>LassoLars<i><br><i>SGDRegressor<i><br><i>RandomForestRegressor<i><br><i>ExtraTreesRegressor<i>|\n",
    "|**path**|Relative path to the project folder. AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder.|\n",
    "    \n",
    "For the optimal performance of `AutomatedML` it is recommended to run at least 100 iterations. Due to the lab's time constraints we will only run 25 iterations. We will also limit a number of alogirthms tried using the `blacklist_algos` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "import logging\n",
    "\n",
    "\n",
    "automl_config = AutoMLConfig(#compute_target = bai_compute_target,\n",
    "                             run_configuration = run_config,\n",
    "                             task = 'classification',\n",
    "                             num_classes = 6,\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             primary_metric = 'accuracy',\n",
    "                             max_time_sec = 1800,\n",
    "                             iterations = 25,\n",
    "                             concurrent_iterations = 5,\n",
    "                             max_cores_per_iteration = 1,\n",
    "                             preprocess = False,\n",
    "                             exit_score = 0.96,\n",
    "                             blacklist_algos = ['KNeighborsClassifier',\n",
    "                                                'LinearSVMWrapper',\n",
    "                                                'NBWrapper',\n",
    "                                                'BernoulliNB',\n",
    "                                                'SGDClassifierWrapper'],\n",
    "                             verbosity = logging.INFO,\n",
    "                             path = script_folder,\n",
    "                             data_script = os.path.join(script_folder, 'get_data.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Automated ML job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>aerial-automatedML</td><td>AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994</td><td>automl</td><td>Preparing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamllab/providers/Microsoft.MachineLearningServices/workspaces/jkamllab/experiments/aerial-automatedML/runs/AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: aerial-automatedML,\n",
       "Id: AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994,\n",
       "Type: automl,\n",
       "Status: Preparing)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = {\"Desc\": \"automated ml\"}\n",
    "run = exp.submit(config=automl_config, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to experiment returns `AutoMLRun` object that can be used to track the run.\n",
    "\n",
    "Since the call is asynchronous, it reports a **Preparing** or **Running** state as soon as the job is started.\n",
    "\n",
    "Here is what's happening while you wait:\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the RunConfiguration. The image is uploaded to the workspace. This happens only once for each Python environment since the container is cached for subsequent runs.  During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Scaling**: If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically. \n",
    "\n",
    "- **Running**: In this stage, the Automated ML takes over and starts running experiments\n",
    "\n",
    "\n",
    "\n",
    "You can check the progress of a running job in multiple ways: Azure Portal, AML Widgets or streaming logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor the run.\n",
    "\n",
    "We will use AML Widget to monitor the run. The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
    "\n",
    "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219e82e8f8cd4ccc9a6027e2243c103e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoML(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waiting until the run finishes\n",
    "\n",
    "`wait_for_complettion` method will block till the run finishes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "***********************************************************************************************\n",
      "\n",
      " ITERATION     PIPELINE                               DURATION                METRIC      BEST\n",
      "         0     StandardScalerWrapper ExtraTreesClassif15                       0.775     0.775\n",
      "         1     MaxAbsScaler DecisionTreeClassifier    8                        0.470     0.775\n",
      "         2     MaxAbsScaler GradientBoostingClassifier6                        0.167     0.775\n",
      "         3     SparseNormalizer DecisionTreeClassifier1                        0.519     0.775\n",
      "         5     MaxAbsScaler LightGBMClassifier        52                       0.819     0.819\n",
      "         6     SparseNormalizer GradientBoostingClassi4                        0.167     0.819\n",
      "         4     StandardScalerWrapper ExtraTreesClassif14                       0.748     0.819\n",
      "         7     MinMaxScaler DecisionTreeClassifier    3                        0.328     0.819\n",
      "         9     RobustScaler ExtraTreesClassifier      3                        0.167     0.819\n",
      "         8     MaxAbsScaler DecisionTreeClassifier    1                        0.426     0.819\n",
      "        10     MaxAbsScaler RandomForestClassifier    1                        0.167     0.819\n",
      "        13     StandardScalerWrapper ExtraTreesClassif151                      0.802     0.819\n",
      "        14     PCA GradientBoostingClassifier         11                       0.167     0.819\n",
      "        11     SparseNormalizer LightGBMClassifier    212                      0.949     0.949\n",
      "        12     MaxAbsScaler LightGBMClassifier        315                      0.956     0.956\n",
      "        15     PCA RandomForestClassifier             11                       0.167     0.956\n",
      "        18     StandardScalerWrapper LogisticRegressio29                       0.949     0.956\n",
      "        17     RobustScaler RandomForestClassifier    88                       0.820     0.956\n",
      "        19     SparseNormalizer LogisticRegression    148                      0.958     0.958\n",
      "        21     MaxAbsScaler LogisticRegression        51                       0.956     0.958\n",
      "        22     PCA LogisticRegression                 46                       0.955     0.958\n",
      "        24     TruncatedSVDWrapper LogisticRegression 5                        0.909     0.958\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994',\n",
       " 'target': 'batchaicls',\n",
       " 'status': 'Running',\n",
       " 'startTimeUtc': '2018-11-05T16:37:52.308266Z',\n",
       " 'properties': {'num_iterations': '25',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'accuracy',\n",
       "  'train_split': '0',\n",
       "  'max_time_seconds': '1800',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': None,\n",
       "  'target': 'batchaicls',\n",
       "  'RawAMLSettingsString': \"{'name': 'aerial-automatedML', 'path': './script', 'subscription_id': '952a710c-8d9c-40c1-9fec-f752138cc0b3', 'resource_group': 'jkamllab', 'workspace_name': 'jkamllab', 'iterations': 25, 'primary_metric': 'accuracy', 'data_script': './script/get_data.py', 'compute_target': 'batchaicls', 'task_type': 'classification', 'validation_size': 0.0, 'n_cross_validations': None, 'y_min': None, 'y_max': None, 'num_classes': 6, 'preprocess': False, 'lag_length': 0, 'max_cores_per_iteration': 1, 'concurrent_iterations': 5, 'max_time_sec': 1800, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'exit_time_sec': None, 'exit_score': 0.96, 'blacklist_algos': ['KNeighborsClassifier', 'LinearSVMWrapper', 'NBWrapper', 'BernoulliNB', 'SGDClassifierWrapper', 'GradientBoostingClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'service_url': 'https://eastus2.experiments.azureml.net', 'sdk_url': None, 'sdk_packages': None, 'telemetry_verbosity': 'NOTSET', 'send_telemetry': False, 'metrics': None, 'enable_ensembling': False, 'ensemble_iterations': 1, 'metric_operation': 'maximize'}\",\n",
       "  'AMLSettingsJsonString': '{\"name\": \"aerial-automatedML\", \"path\": \"./script\", \"subscription_id\": \"952a710c-8d9c-40c1-9fec-f752138cc0b3\", \"resource_group\": \"jkamllab\", \"workspace_name\": \"jkamllab\", \"iterations\": 25, \"primary_metric\": \"accuracy\", \"data_script\": \"./script/get_data.py\", \"compute_target\": \"batchaicls\", \"task_type\": \"classification\", \"validation_size\": 0.0, \"n_cross_validations\": null, \"y_min\": null, \"y_max\": null, \"num_classes\": 6, \"preprocess\": false, \"lag_length\": 0, \"max_cores_per_iteration\": 1, \"concurrent_iterations\": 5, \"max_time_sec\": 1800, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"exit_time_sec\": null, \"exit_score\": 0.96, \"blacklist_algos\": [\"KNeighborsClassifier\", \"LinearSVMWrapper\", \"NBWrapper\", \"BernoulliNB\", \"SGDClassifierWrapper\", \"GradientBoostingClassifier\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"service_url\": \"https://eastus2.experiments.azureml.net\", \"sdk_url\": null, \"sdk_packages\": null, \"telemetry_verbosity\": \"NOTSET\", \"send_telemetry\": false, \"metrics\": null, \"enable_ensembling\": false, \"ensemble_iterations\": 1, \"metric_operation\": \"maximize\"}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'SetupRunId': 'AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994_setup',\n",
       "  'snapshotId': '29665ba1-e718-4c3c-b56e-01a8b517c63d',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"dataset_classes\": 6, \"dataset_features\": 2048, \"dataset_samples\": 19882, \"is_sparse\": false}'},\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait until the run finishes.\n",
    "run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cancelling Runs\n",
    "\n",
    "You can cancel ongoing remote runs using the `cancel` and `cancel_iteration` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel the ongoing experiment and stop scheduling new iterations.\n",
    "# run.cancel()\n",
    "\n",
    "# Cancel iteration 1 and move onto iteration 2.\n",
    "# run.cancel_iteration(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze the run\n",
    "\n",
    "You can  use SDK methods to fetch all the child runs and see individual metrics that we log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC_macro</th>\n",
       "      <td>0.953789</td>\n",
       "      <td>0.820450</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.794056</td>\n",
       "      <td>0.952080</td>\n",
       "      <td>0.963538</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.705291</td>\n",
       "      <td>0.766178</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972750</td>\n",
       "      <td>0.995254</td>\n",
       "      <td>0.997827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996104</td>\n",
       "      <td>0.995687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_micro</th>\n",
       "      <td>0.958286</td>\n",
       "      <td>0.854301</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.841006</td>\n",
       "      <td>0.957627</td>\n",
       "      <td>0.967422</td>\n",
       "      <td>0.499910</td>\n",
       "      <td>0.766510</td>\n",
       "      <td>0.805903</td>\n",
       "      <td>0.500362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976220</td>\n",
       "      <td>0.996018</td>\n",
       "      <td>0.998164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996685</td>\n",
       "      <td>0.996218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_weighted</th>\n",
       "      <td>0.953812</td>\n",
       "      <td>0.820450</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.794047</td>\n",
       "      <td>0.952067</td>\n",
       "      <td>0.963556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.705367</td>\n",
       "      <td>0.766109</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.995253</td>\n",
       "      <td>0.997828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996106</td>\n",
       "      <td>0.995688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.469683</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>0.518552</td>\n",
       "      <td>0.748416</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.166516</td>\n",
       "      <td>0.327602</td>\n",
       "      <td>0.426244</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>0.948869</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>0.951584</td>\n",
       "      <td>0.955656</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_max</th>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.469683</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>0.518552</td>\n",
       "      <td>0.748416</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>0.948869</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.956109</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.957919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_macro</th>\n",
       "      <td>0.845132</td>\n",
       "      <td>0.400364</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.395907</td>\n",
       "      <td>0.841569</td>\n",
       "      <td>0.869894</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.276505</td>\n",
       "      <td>0.372594</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899635</td>\n",
       "      <td>0.980818</td>\n",
       "      <td>0.989903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986805</td>\n",
       "      <td>0.984605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.960002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_micro</th>\n",
       "      <td>0.847211</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.166713</td>\n",
       "      <td>0.475188</td>\n",
       "      <td>0.845624</td>\n",
       "      <td>0.887821</td>\n",
       "      <td>0.166615</td>\n",
       "      <td>0.321624</td>\n",
       "      <td>0.449343</td>\n",
       "      <td>0.166810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899563</td>\n",
       "      <td>0.984645</td>\n",
       "      <td>0.992048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.988670</td>\n",
       "      <td>0.986573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_weighted</th>\n",
       "      <td>0.845179</td>\n",
       "      <td>0.400349</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.395894</td>\n",
       "      <td>0.841538</td>\n",
       "      <td>0.869972</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.276553</td>\n",
       "      <td>0.372492</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899680</td>\n",
       "      <td>0.980820</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.986812</td>\n",
       "      <td>0.984611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.864983</td>\n",
       "      <td>0.681796</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.711179</td>\n",
       "      <td>0.849139</td>\n",
       "      <td>0.891355</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.596241</td>\n",
       "      <td>0.655747</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.892156</td>\n",
       "      <td>0.969318</td>\n",
       "      <td>0.974747</td>\n",
       "      <td>0.970946</td>\n",
       "      <td>0.973386</td>\n",
       "      <td>0.972845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.741358</td>\n",
       "      <td>0.316692</td>\n",
       "      <td>0.047693</td>\n",
       "      <td>0.414248</td>\n",
       "      <td>0.709692</td>\n",
       "      <td>0.815252</td>\n",
       "      <td>0.047582</td>\n",
       "      <td>0.165204</td>\n",
       "      <td>0.306100</td>\n",
       "      <td>0.047693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789452</td>\n",
       "      <td>0.948944</td>\n",
       "      <td>0.957946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955644</td>\n",
       "      <td>0.954740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.469683</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>0.518552</td>\n",
       "      <td>0.748416</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.166516</td>\n",
       "      <td>0.327602</td>\n",
       "      <td>0.426244</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>0.948869</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955656</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.741445</td>\n",
       "      <td>0.316659</td>\n",
       "      <td>0.047779</td>\n",
       "      <td>0.414177</td>\n",
       "      <td>0.709592</td>\n",
       "      <td>0.815332</td>\n",
       "      <td>0.047539</td>\n",
       "      <td>0.165503</td>\n",
       "      <td>0.306036</td>\n",
       "      <td>0.047779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789524</td>\n",
       "      <td>0.948949</td>\n",
       "      <td>0.957954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955659</td>\n",
       "      <td>0.954756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>0.900068</td>\n",
       "      <td>1.150839</td>\n",
       "      <td>1.791760</td>\n",
       "      <td>1.230146</td>\n",
       "      <td>0.860093</td>\n",
       "      <td>1.790924</td>\n",
       "      <td>1.791771</td>\n",
       "      <td>1.414085</td>\n",
       "      <td>1.322407</td>\n",
       "      <td>1.791760</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.299724</td>\n",
       "      <td>0.122906</td>\n",
       "      <td>0.156990</td>\n",
       "      <td>0.152632</td>\n",
       "      <td>0.184466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_macro_recall</th>\n",
       "      <td>0.729937</td>\n",
       "      <td>0.363597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422370</td>\n",
       "      <td>0.698306</td>\n",
       "      <td>0.782690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192412</td>\n",
       "      <td>0.311506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784291</td>\n",
       "      <td>0.938634</td>\n",
       "      <td>0.949492</td>\n",
       "      <td>0.941891</td>\n",
       "      <td>0.946769</td>\n",
       "      <td>0.945688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.890379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_macro</th>\n",
       "      <td>0.790811</td>\n",
       "      <td>0.241293</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>0.344872</td>\n",
       "      <td>0.773678</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.027753</td>\n",
       "      <td>0.111053</td>\n",
       "      <td>0.259517</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842988</td>\n",
       "      <td>0.949094</td>\n",
       "      <td>0.958146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955713</td>\n",
       "      <td>0.954811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_micro</th>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.469683</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>0.518552</td>\n",
       "      <td>0.748416</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.166516</td>\n",
       "      <td>0.327602</td>\n",
       "      <td>0.426244</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>0.948869</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955656</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_weighted</th>\n",
       "      <td>0.790778</td>\n",
       "      <td>0.241253</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.344813</td>\n",
       "      <td>0.773722</td>\n",
       "      <td>0.817265</td>\n",
       "      <td>0.027728</td>\n",
       "      <td>0.111254</td>\n",
       "      <td>0.259431</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842948</td>\n",
       "      <td>0.949097</td>\n",
       "      <td>0.958154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955727</td>\n",
       "      <td>0.954830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_macro</th>\n",
       "      <td>0.774947</td>\n",
       "      <td>0.469664</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.518641</td>\n",
       "      <td>0.748589</td>\n",
       "      <td>0.818908</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.327010</td>\n",
       "      <td>0.426255</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820242</td>\n",
       "      <td>0.948862</td>\n",
       "      <td>0.957910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955640</td>\n",
       "      <td>0.954740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_micro</th>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.469683</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>0.518552</td>\n",
       "      <td>0.748416</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.166516</td>\n",
       "      <td>0.327602</td>\n",
       "      <td>0.426244</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>0.948869</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955656</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_weighted</th>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.469683</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>0.518552</td>\n",
       "      <td>0.748416</td>\n",
       "      <td>0.819005</td>\n",
       "      <td>0.166516</td>\n",
       "      <td>0.327602</td>\n",
       "      <td>0.426244</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820362</td>\n",
       "      <td>0.948869</td>\n",
       "      <td>0.957919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955656</td>\n",
       "      <td>0.954751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_accuracy</th>\n",
       "      <td>0.775279</td>\n",
       "      <td>0.469702</td>\n",
       "      <td>0.167270</td>\n",
       "      <td>0.518463</td>\n",
       "      <td>0.748244</td>\n",
       "      <td>0.819101</td>\n",
       "      <td>0.166365</td>\n",
       "      <td>0.328194</td>\n",
       "      <td>0.426234</td>\n",
       "      <td>0.167270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.820482</td>\n",
       "      <td>0.948876</td>\n",
       "      <td>0.957927</td>\n",
       "      <td>0.951592</td>\n",
       "      <td>0.955672</td>\n",
       "      <td>0.954763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.908545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0         1         2         3   \\\n",
       "AUC_macro                         0.953789  0.820450  0.500000  0.794056   \n",
       "AUC_micro                         0.958286  0.854301  0.500000  0.841006   \n",
       "AUC_weighted                      0.953812  0.820450  0.500000  0.794047   \n",
       "accuracy                          0.775113  0.469683  0.166968  0.518552   \n",
       "accuracy_max                      0.775113  0.469683  0.166968  0.518552   \n",
       "average_precision_score_macro     0.845132  0.400364  0.166667  0.395907   \n",
       "average_precision_score_micro     0.847211  0.461300  0.166713  0.475188   \n",
       "average_precision_score_weighted  0.845179  0.400349  0.166667  0.395894   \n",
       "balanced_accuracy                 0.864983  0.681796  0.500000  0.711179   \n",
       "f1_score_macro                    0.741358  0.316692  0.047693  0.414248   \n",
       "f1_score_micro                    0.775113  0.469683  0.166968  0.518552   \n",
       "f1_score_weighted                 0.741445  0.316659  0.047779  0.414177   \n",
       "log_loss                          0.900068  1.150839  1.791760  1.230146   \n",
       "norm_macro_recall                 0.729937  0.363597  0.000000  0.422370   \n",
       "precision_score_macro             0.790811  0.241293  0.027828  0.344872   \n",
       "precision_score_micro             0.775113  0.469683  0.166968  0.518552   \n",
       "precision_score_weighted          0.790778  0.241253  0.027878  0.344813   \n",
       "recall_score_macro                0.774947  0.469664  0.166667  0.518641   \n",
       "recall_score_micro                0.775113  0.469683  0.166968  0.518552   \n",
       "recall_score_weighted             0.775113  0.469683  0.166968  0.518552   \n",
       "weighted_accuracy                 0.775279  0.469702  0.167270  0.518463   \n",
       "\n",
       "                                        4         5         6         7   \\\n",
       "AUC_macro                         0.952080  0.963538  0.500000  0.705291   \n",
       "AUC_micro                         0.957627  0.967422  0.499910  0.766510   \n",
       "AUC_weighted                      0.952067  0.963556  0.500000  0.705367   \n",
       "accuracy                          0.748416  0.819005  0.166516  0.327602   \n",
       "accuracy_max                      0.748416  0.819005  0.775113  0.775113   \n",
       "average_precision_score_macro     0.841569  0.869894  0.166667  0.276505   \n",
       "average_precision_score_micro     0.845624  0.887821  0.166615  0.321624   \n",
       "average_precision_score_weighted  0.841538  0.869972  0.166667  0.276553   \n",
       "balanced_accuracy                 0.849139  0.891355  0.500000  0.596241   \n",
       "f1_score_macro                    0.709692  0.815252  0.047582  0.165204   \n",
       "f1_score_micro                    0.748416  0.819005  0.166516  0.327602   \n",
       "f1_score_weighted                 0.709592  0.815332  0.047539  0.165503   \n",
       "log_loss                          0.860093  1.790924  1.791771  1.414085   \n",
       "norm_macro_recall                 0.698306  0.782690  0.000000  0.192412   \n",
       "precision_score_macro             0.773678  0.817204  0.027753  0.111053   \n",
       "precision_score_micro             0.748416  0.819005  0.166516  0.327602   \n",
       "precision_score_weighted          0.773722  0.817265  0.027728  0.111254   \n",
       "recall_score_macro                0.748589  0.818908  0.166667  0.327010   \n",
       "recall_score_micro                0.748416  0.819005  0.166516  0.327602   \n",
       "recall_score_weighted             0.748416  0.819005  0.166516  0.327602   \n",
       "weighted_accuracy                 0.748244  0.819101  0.166365  0.328194   \n",
       "\n",
       "                                        8         9     ...           15  16  \\\n",
       "AUC_macro                         0.766178  0.500000    ...     0.500000 NaN   \n",
       "AUC_micro                         0.805903  0.500362    ...     0.500000 NaN   \n",
       "AUC_weighted                      0.766109  0.500000    ...     0.500000 NaN   \n",
       "accuracy                          0.426244  0.166968    ...     0.166968 NaN   \n",
       "accuracy_max                      0.775113  0.819005    ...     0.819005 NaN   \n",
       "average_precision_score_macro     0.372594  0.166667    ...     0.166667 NaN   \n",
       "average_precision_score_micro     0.449343  0.166810    ...     0.166713 NaN   \n",
       "average_precision_score_weighted  0.372492  0.166667    ...     0.166667 NaN   \n",
       "balanced_accuracy                 0.655747  0.500000    ...     0.500000 NaN   \n",
       "f1_score_macro                    0.306100  0.047693    ...     0.047693 NaN   \n",
       "f1_score_micro                    0.426244  0.166968    ...     0.166968 NaN   \n",
       "f1_score_weighted                 0.306036  0.047779    ...     0.047779 NaN   \n",
       "log_loss                          1.322407  1.791760    ...     1.791760 NaN   \n",
       "norm_macro_recall                 0.311506  0.000000    ...     0.000000 NaN   \n",
       "precision_score_macro             0.259517  0.027828    ...     0.027828 NaN   \n",
       "precision_score_micro             0.426244  0.166968    ...     0.166968 NaN   \n",
       "precision_score_weighted          0.259431  0.027878    ...     0.027878 NaN   \n",
       "recall_score_macro                0.426255  0.166667    ...     0.166667 NaN   \n",
       "recall_score_micro                0.426244  0.166968    ...     0.166968 NaN   \n",
       "recall_score_weighted             0.426244  0.166968    ...     0.166968 NaN   \n",
       "weighted_accuracy                 0.426234  0.167270    ...     0.167270 NaN   \n",
       "\n",
       "                                        17        18        19        20  \\\n",
       "AUC_macro                         0.972750  0.995254  0.997827       NaN   \n",
       "AUC_micro                         0.976220  0.996018  0.998164       NaN   \n",
       "AUC_weighted                      0.972763  0.995253  0.997828       NaN   \n",
       "accuracy                          0.820362  0.948869  0.957919  0.951584   \n",
       "accuracy_max                      0.820362  0.948869  0.957919       NaN   \n",
       "average_precision_score_macro     0.899635  0.980818  0.989903       NaN   \n",
       "average_precision_score_micro     0.899563  0.984645  0.992048       NaN   \n",
       "average_precision_score_weighted  0.899680  0.980820  0.989907       NaN   \n",
       "balanced_accuracy                 0.892156  0.969318  0.974747  0.970946   \n",
       "f1_score_macro                    0.789452  0.948944  0.957946       NaN   \n",
       "f1_score_micro                    0.820362  0.948869  0.957919       NaN   \n",
       "f1_score_weighted                 0.789524  0.948949  0.957954       NaN   \n",
       "log_loss                          0.999974  0.299724  0.122906  0.156990   \n",
       "norm_macro_recall                 0.784291  0.938634  0.949492  0.941891   \n",
       "precision_score_macro             0.842988  0.949094  0.958146       NaN   \n",
       "precision_score_micro             0.820362  0.948869  0.957919       NaN   \n",
       "precision_score_weighted          0.842948  0.949097  0.958154       NaN   \n",
       "recall_score_macro                0.820242  0.948862  0.957910       NaN   \n",
       "recall_score_micro                0.820362  0.948869  0.957919       NaN   \n",
       "recall_score_weighted             0.820362  0.948869  0.957919       NaN   \n",
       "weighted_accuracy                 0.820482  0.948876  0.957927  0.951592   \n",
       "\n",
       "                                        21        22  23        24  \n",
       "AUC_macro                         0.996104  0.995687 NaN  0.990668  \n",
       "AUC_micro                         0.996685  0.996218 NaN  0.992133  \n",
       "AUC_weighted                      0.996106  0.995688 NaN  0.990661  \n",
       "accuracy                          0.955656  0.954751 NaN  0.908597  \n",
       "accuracy_max                      0.956109  0.957919 NaN  0.957919  \n",
       "average_precision_score_macro     0.986805  0.984605 NaN  0.960002  \n",
       "average_precision_score_micro     0.988670  0.986573 NaN  0.968995  \n",
       "average_precision_score_weighted  0.986812  0.984611 NaN  0.959967  \n",
       "balanced_accuracy                 0.973386  0.972845 NaN  0.945183  \n",
       "f1_score_macro                    0.955644  0.954740 NaN  0.909143  \n",
       "f1_score_micro                    0.955656  0.954751 NaN  0.908597  \n",
       "f1_score_weighted                 0.955659  0.954756 NaN  0.909092  \n",
       "log_loss                          0.152632  0.184466 NaN  0.295907  \n",
       "norm_macro_recall                 0.946769  0.945688 NaN  0.890379  \n",
       "precision_score_macro             0.955713  0.954811 NaN  0.910441  \n",
       "precision_score_micro             0.955656  0.954751 NaN  0.908597  \n",
       "precision_score_weighted          0.955727  0.954830 NaN  0.910392  \n",
       "recall_score_macro                0.955640  0.954740 NaN  0.908650  \n",
       "recall_score_micro                0.955656  0.954751 NaN  0.908597  \n",
       "recall_score_weighted             0.955656  0.954751 NaN  0.908597  \n",
       "weighted_accuracy                 0.955672  0.954763 NaN  0.908545  \n",
       "\n",
       "[21 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "children = list(run.get_children())\n",
    "metricslist = {}\n",
    "for child in children:\n",
    "    properties = child.get_properties()\n",
    "    metrics = {k: v for k, v in child.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model\n",
    "\n",
    "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*.\n",
    "\n",
    "#### Best model based on the primary metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: aerial-automatedML,\n",
      "Id: AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994_19,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('SparseNormalizer', <automl.client.core.common.model_wrappers.SparseNormalizer object at 0x1a33394400>), ('LogisticRegression', LogisticRegression(C=7.9060432109076855, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
      "          random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "          warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model based on any metric\n",
    "You can also retrieve the best model based on an arbitrary metric. For example, we will retrieve the model with the highest AUC value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: aerial-automatedML,\n",
      "Id: AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994_19,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('SparseNormalizer', <automl.client.core.common.model_wrappers.SparseNormalizer object at 0x1a342fae48>), ('LogisticRegression', LogisticRegression(C=7.9060432109076855, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='multinomial', n_jobs=1, penalty='l2',\n",
      "          random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "          warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "lookup_metric = \"AUC_weighted\"\n",
    "best_run_auc, fitted_model_best_auc = run.get_output(metric = lookup_metric)\n",
    "print(best_run_auc)\n",
    "print(fitted_model_best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model from a specific iteration\n",
    "Show the run and the model from the third iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: aerial-automatedML,\n",
      "Id: AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994_3,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('SparseNormalizer', <automl.client.core.common.model_wrappers.SparseNormalizer object at 0x1a43883400>), ('DecisionTreeClassifier', DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
      "            max_depth=None, max_features=0.7, max_leaf_nodes=None,\n",
      "            min_impurity_de...    min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random'))])\n"
     ]
    }
   ],
   "source": [
    "iteration = 3\n",
    "third_run, third_model = run.get_output(iteration=iteration)\n",
    "print(third_run)\n",
    "print(third_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the best model\n",
    "\n",
    "You can use `AutoMLRun` to register the trained model with AML Model Registry.\n",
    "\n",
    "If neither `metric` nor `iteration` are specified in the `register_model` call, the iteration with the best primary metric is registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model AutoML73bdf26bebest\n",
      "Model ID: AutoML73bdf26bebest\n",
      "Run ID: AutoML_73bdf26b-ec03-4eb3-9c98-72e6d99e8994\n"
     ]
    }
   ],
   "source": [
    "description = 'Aerial Classifier Model'\n",
    "\n",
    "tags = {\"Featurizer\": \"ResNet50\" }\n",
    "model = run.register_model(description = description, tags = tags)\n",
    "\n",
    "print(\"Model ID:\", run.model_id)\n",
    "print(\"Run ID:\", run.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save *Model ID* and *Run ID*. You will need these values in the deployment lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "The model is ready for deployment. In the next lab you will deploy the model you registered in the previous step to Azure Container Instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "Before you move to the next step, you can delete the BAI cluster. We will not need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bai_compute_target.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
