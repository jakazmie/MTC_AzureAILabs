{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Model training and evaluation\n",
    "In this lab we will train a multinomial classification model using the bottleneck features created in Lab 2.\n",
    "\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/tlcl.png)\n",
    "\n",
    "We will start with training a simple logistic regression model in a local environment to validate that the bottleneck features can improve our classifier. We will then use the Azure ML feature called `Automated ML` to find the most optimal model for our image classification task.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/automated-machine-learning.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.74\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AML workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/MTC_AzureAILabs/DataScienceTrack/01-aml-walkthrough/aml_config/config.json\n",
      "jkamllab\n",
      "jkamllab\n",
      "eastus2\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "import os\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic regression model locally\n",
    "\n",
    "We will start by training a logistic regression model locally using the bottleneck features created in Lab 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download bottleneck features\n",
    "\n",
    "In the previous lab, the bottleneck features have been uploaded to the `bottleneck_features`folder in the default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'bottleneck_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aerial_bottleneck_resnet50_brainwave.h5  aerial_bottleneck_resnet50.h5\r\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "ds.download(target_path='.', prefix=data_folder, overwrite=True)\n",
    "!ls bottleneck_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train logistic regression using bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load features and labels into numpy arrays\n",
    "file_name = os.path.join(data_folder, 'aerial_bottleneck_resnet50_brainwave.h5')\n",
    "with h5py.File(file_name, \"r\") as hfile:\n",
    "    features = np.array(hfile.get('features'))\n",
    "    labels = np.array(hfile.get('labels'))\n",
    " \n",
    "# Split the data into training and validation partitions   \n",
    "X_train, X_validation, y_train, y_validation = train_test_split(features, labels,\n",
    "                                                               test_size=0.1,\n",
    "                                                               shuffle=True,\n",
    "                                                               stratify=labels)\n",
    "    \n",
    "# Train logistics regresssion model\n",
    "reg = 0.1\n",
    "clf = LogisticRegression(\n",
    "        C=1.0/reg, \n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        random_state=1)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is: 0.9407239819004525\n"
     ]
    }
   ],
   "source": [
    "# Validate\n",
    "y_hat = clf.predict(X_validation)\n",
    "    \n",
    "# Calculate accuracy \n",
    "acc = np.average(y_hat == y_validation)\n",
    "print('Validation accuracy is:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, the performance of the model trained on the bottleneck features is much better then the performance of the model trained on raw images. Our approach works. The next step is to find the most optimal classifier. We will accomplish that using the AML feature called `Automated ML`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated model selection\n",
    "\n",
    "Automated machine learning (automated ML) automatically picks an algorithm and hyperparameters that optimize a given  primary metric. The model can be downloaded to be further customized as well. There are several options that you can use to configure Automated ML experiments. In this section of the lab we will go through the steps to configure and run the `Automated ML` job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Experiment\n",
    "\n",
    "We will create a new experiment to manage `Automated ML' runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'aerial-automatedML'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create  compute target\n",
    "\n",
    "Automated ML supports running concurrent experiments on Azure Batch AI clusters. This can significantly shorten the model selection and hyperparameter optimization process. \n",
    "\n",
    "**Note:** The creation of the Batch AI cluster can take over 10 minutes, please be patient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpudsvm VirtualMachine\n",
      "batchaicls BatchAI\n",
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import BatchAiCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "batchai_cluster_name = \"batchaicls\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "for ct_name, ct in ws.compute_targets.items():\n",
    "    print(ct.name, ct.type)\n",
    "    if (ct.name == batchai_cluster_name and ct.type == 'BatchAI'):\n",
    "        found = True\n",
    "        print('Found existing compute target.')\n",
    "        bai_compute_target = ct\n",
    "        break\n",
    "        \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = BatchAiCompute.provisioning_configuration(vm_size = \"STANDARD_DS2_V2\", \n",
    "                                                                autoscale_enabled = True,\n",
    "                                                                cluster_min_nodes = 1, \n",
    "                                                                cluster_max_nodes = 5)\n",
    "\n",
    "    # Create the cluster.\n",
    "    bai_compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
    "    \n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "    bai_compute_target.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Get Data script\n",
    "\n",
    "If you are using a remote compute to run your Automated ML experiments, the data fetch must be wrapped in a separate python script that implements `get_data()` function. This script is run on the remote compute where the automated ML experiment is run. `get_data()` eliminates the need to fetch the data over the wire for each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "script_name = 'get_data.py'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/get_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/get_data.py\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_data():\n",
    "    # Load bottleneck features\n",
    "    data_folder = os.environ[\"AZUREML_DATAREFERENCE_workspacefilestore\"]\n",
    "    file_name = os.path.join(data_folder, 'aerial_bottleneck_resnet50_brainwave.h5')\n",
    "    \n",
    "    print(\"Data folder:\", data_folder)\n",
    "    print(\"Bottleneck features file:\", file_name)\n",
    "    print(\"Data folder content:\", os.listdir(data_folder))\n",
    "    \n",
    "    with h5py.File(file_name, \"r\") as hfile:\n",
    "        features = np.array(hfile.get('features'))\n",
    "        labels = np.array(hfile.get('labels'))\n",
    "        \n",
    "    # Split the data into training and validation partitions   \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(features, labels,\n",
    "                                                               test_size=0.1,\n",
    "                                                               shuffle=True,\n",
    "                                                               stratify=labels)\n",
    "        \n",
    "\n",
    "    return {'X': X_train, 'y': y_train, 'X_valid': X_validation, 'y_valid': y_validation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure datastore and data reference\n",
    "\n",
    "The bottleneck files have been uploaded to the workspace's default datastore during the previous step. We will download the files onto the nodes of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default datastore for training data: \n",
      "workspacefilestore AzureFile jkamllab3650394639 azureml-filestore-bc740c20-4b07-49e7-92ba-c5bf27a7cb86\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for training data: \")\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                   path_on_datastore='bottleneck_features', \n",
    "                   path_on_compute='bottleneck_features',\n",
    "                   mode='download', # download files from datastore to compute target\n",
    "                   overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Docker run configuration\n",
    "\n",
    "We will run `Automated ML` jobs in a custom docker image that will include dependencies required by `get_data()` script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Run\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# create a new RunConfig object\n",
    "run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Azure Batch AI cluster for Automated ML jobs require docker.\n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# Set compute target to BAI cluster\n",
    "run_config.target = bai_compute_target.name\n",
    "\n",
    "# Set data references\n",
    "run_config.data_references = {ds.name: dr}\n",
    "\n",
    "# specify packages required by get_data\n",
    "run_config.environment.python.conda_dependencies = \\\n",
    "   CondaDependencies.create(conda_packages=['h5py'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Automated ML run.\n",
    "\n",
    "Automated ML runs can be controlled using a number of configuration parameters. \n",
    "\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|classification or regression|\n",
    "|**primary_metric**|This is the metric that you want to optimize.<br> Classification supports the following primary metrics <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>balanced_accuracy</i><br><i>average_precision_score_weighted</i><br><i>precision_score_weighted</i>|\n",
    "|**max_time_sec**|Time limit in seconds for each iteration|\n",
    "|**iterations**|Number of iterations. In each iteration Auto ML trains a specific pipeline with the data|\n",
    "|**n_cross_validations**|Number of cross validation splits|\n",
    "|**concurrent_iterations**|Max number of iterations that would be executed in parallel. |\n",
    "|**preprocess**| *True/False* <br>Setting this to *True* enables Auto ML to perform preprocessing <br>on the input to handle *missing data*, and perform some common *feature extraction*|\n",
    "|**max_cores_per_iteration**| Indicates how many cores on the compute target would be used to train a single pipeline.<br> Default is *1*, you can set it to *-1* to use all cores|\n",
    "|**exit_score**|*double* value indicating the target for *primary_metric*. <br>Once the target is surpassed the run terminates.|\n",
    "|**blacklist_algos**|*List* of *strings* indicating machine learning algorithms for AutoML to avoid in this run.<br><br> Allowed values for **Classification**<br><i>LogisticRegression</i><br><i>SGDClassifierWrapper</i><br><i>NBWrapper</i><br><i>BernoulliNB</i><br><i>SVCWrapper</i><br><i>LinearSVMWrapper</i><br><i>KNeighborsClassifier</i><br><i>GradientBoostingClassifier</i><br><i>DecisionTreeClassifier</i><br><i>RandomForestClassifier</i><br><i>ExtraTreesClassifier</i><br><i>LightGBMClassifier</i><br><br>Allowed values for **Regression**<br><i>ElasticNet<i><br><i>GradientBoostingRegressor<i><br><i>DecisionTreeRegressor<i><br><i>KNeighborsRegressor<i><br><i>LassoLars<i><br><i>SGDRegressor<i><br><i>RandomForestRegressor<i><br><i>ExtraTreesRegressor<i>|\n",
    "|**path**|Relative path to the project folder. AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder.|\n",
    "    \n",
    "For the optimal performance of `AutomatedML` it is recommended to run at least 100 iterations. Due to the lab's time constraints we will only run 25 iterations. We will also limit a number of alogirthms tried using the `blacklist_algos` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "import logging\n",
    "\n",
    "\n",
    "automl_config = AutoMLConfig(run_configuration = run_config,\n",
    "                             task = 'classification',\n",
    "                             num_classes = 6,\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             primary_metric = 'accuracy',\n",
    "                             max_time_sec = 1800,\n",
    "                             iterations = 25,\n",
    "                             concurrent_iterations = 5,\n",
    "                             max_cores_per_iteration = 1,\n",
    "                             preprocess = False,\n",
    "                             exit_score = 0.96,\n",
    "                             blacklist_algos = ['KNeighborsClassifier',\n",
    "                                                'LinearSVMWrapper',\n",
    "                                                'NBWrapper',\n",
    "                                                'BernoulliNB',\n",
    "                                                'GradientBoostingClassifier',\n",
    "                                                'SGDClassifierWrapper'],\n",
    "                             verbosity = logging.INFO,\n",
    "                             path = script_folder,\n",
    "                             data_script = os.path.join(script_folder, script_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Automated ML job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>aerial-automatedML</td><td>AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab</td><td>automl</td><td>Preparing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamllab/providers/Microsoft.MachineLearningServices/workspaces/jkamllab/experiments/aerial-automatedML/runs/AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: aerial-automatedML,\n",
       "Id: AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab,\n",
       "Type: automl,\n",
       "Status: Preparing)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = {\"Desc\": \"automated ml\"}\n",
    "run = exp.submit(config=automl_config, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to experiment returns `AutoMLRun` object that can be used to track the run.\n",
    "\n",
    "Since the call is asynchronous, it reports a **Preparing** or **Running** state as soon as the job is started.\n",
    "\n",
    "Here is what's happening while you wait:\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the RunConfiguration. The image is uploaded to the workspace. This happens only once for each Python environment since the container is cached for subsequent runs.  During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Scaling**: If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically. \n",
    "\n",
    "- **Running**: In this stage, the Automated ML takes over and starts running experiments\n",
    "\n",
    "\n",
    "\n",
    "You can check the progress of a running job in multiple ways: Azure Portal, AML Widgets or streaming logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor the run.\n",
    "\n",
    "We will use AML Widget to monitor the run. The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
    "\n",
    "The widget is asynchronous - it does not block the notebook. You can execute other cells while the widget is running.\n",
    "\n",
    "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493047ec55f24be9816d26da8f2ba1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoML(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup', 'display': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5487e59742cb4c27b4dad71c985dbff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup', 'display': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cancelling Runs\n",
    "\n",
    "You can cancel ongoing remote runs using the `cancel` and `cancel_iteration` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel the ongoing experiment and stop scheduling new iterations.\n",
    "# run.cancel()\n",
    "\n",
    "# Cancel iteration 1 and move onto iteration 2.\n",
    "# run.cancel_iteration(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze the run\n",
    "\n",
    "You can  use SDK methods to fetch all the child runs and see individual metrics that we log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC_macro</th>\n",
       "      <td>0.994984</td>\n",
       "      <td>0.928042</td>\n",
       "      <td>0.996208</td>\n",
       "      <td>0.896381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953435</td>\n",
       "      <td>0.995235</td>\n",
       "      <td>0.967551</td>\n",
       "      <td>0.995921</td>\n",
       "      <td>0.989519</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990245</td>\n",
       "      <td>0.991259</td>\n",
       "      <td>0.984884</td>\n",
       "      <td>0.993205</td>\n",
       "      <td>0.993959</td>\n",
       "      <td>0.992093</td>\n",
       "      <td>0.977915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_micro</th>\n",
       "      <td>0.995817</td>\n",
       "      <td>0.936663</td>\n",
       "      <td>0.996712</td>\n",
       "      <td>0.913619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.995898</td>\n",
       "      <td>0.968449</td>\n",
       "      <td>0.996541</td>\n",
       "      <td>0.990898</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991174</td>\n",
       "      <td>0.991835</td>\n",
       "      <td>0.986213</td>\n",
       "      <td>0.993833</td>\n",
       "      <td>0.994692</td>\n",
       "      <td>0.991800</td>\n",
       "      <td>0.977442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_weighted</th>\n",
       "      <td>0.994985</td>\n",
       "      <td>0.928087</td>\n",
       "      <td>0.996208</td>\n",
       "      <td>0.896389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953427</td>\n",
       "      <td>0.995235</td>\n",
       "      <td>0.967548</td>\n",
       "      <td>0.995922</td>\n",
       "      <td>0.989524</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990248</td>\n",
       "      <td>0.991262</td>\n",
       "      <td>0.984875</td>\n",
       "      <td>0.993207</td>\n",
       "      <td>0.993957</td>\n",
       "      <td>0.992095</td>\n",
       "      <td>0.977914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.700905</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.676018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.802715</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912670</td>\n",
       "      <td>0.916290</td>\n",
       "      <td>0.881448</td>\n",
       "      <td>0.933937</td>\n",
       "      <td>0.934389</td>\n",
       "      <td>0.927602</td>\n",
       "      <td>0.828507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_max</th>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.700905</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.676018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.959276</td>\n",
       "      <td>0.959276</td>\n",
       "      <td>0.959276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_macro</th>\n",
       "      <td>0.982230</td>\n",
       "      <td>0.807306</td>\n",
       "      <td>0.984755</td>\n",
       "      <td>0.692530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853102</td>\n",
       "      <td>0.979521</td>\n",
       "      <td>0.884399</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>0.959627</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961124</td>\n",
       "      <td>0.964038</td>\n",
       "      <td>0.939151</td>\n",
       "      <td>0.973369</td>\n",
       "      <td>0.976778</td>\n",
       "      <td>0.968370</td>\n",
       "      <td>0.913278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_micro</th>\n",
       "      <td>0.985318</td>\n",
       "      <td>0.802095</td>\n",
       "      <td>0.987126</td>\n",
       "      <td>0.745719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851408</td>\n",
       "      <td>0.983464</td>\n",
       "      <td>0.895054</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.967261</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967948</td>\n",
       "      <td>0.969875</td>\n",
       "      <td>0.949393</td>\n",
       "      <td>0.977267</td>\n",
       "      <td>0.981050</td>\n",
       "      <td>0.971437</td>\n",
       "      <td>0.914418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_precision_score_weighted</th>\n",
       "      <td>0.982235</td>\n",
       "      <td>0.807421</td>\n",
       "      <td>0.984759</td>\n",
       "      <td>0.692512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853077</td>\n",
       "      <td>0.979524</td>\n",
       "      <td>0.884371</td>\n",
       "      <td>0.983526</td>\n",
       "      <td>0.959650</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961136</td>\n",
       "      <td>0.964058</td>\n",
       "      <td>0.939100</td>\n",
       "      <td>0.973372</td>\n",
       "      <td>0.976763</td>\n",
       "      <td>0.968378</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.947049</td>\n",
       "      <td>0.700740</td>\n",
       "      <td>0.947961</td>\n",
       "      <td>0.676213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785039</td>\n",
       "      <td>0.934839</td>\n",
       "      <td>0.802738</td>\n",
       "      <td>0.947956</td>\n",
       "      <td>0.904940</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912670</td>\n",
       "      <td>0.916263</td>\n",
       "      <td>0.881517</td>\n",
       "      <td>0.933915</td>\n",
       "      <td>0.934416</td>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.828477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_macro</th>\n",
       "      <td>0.947024</td>\n",
       "      <td>0.672795</td>\n",
       "      <td>0.948008</td>\n",
       "      <td>0.633855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782397</td>\n",
       "      <td>0.935211</td>\n",
       "      <td>0.801225</td>\n",
       "      <td>0.948108</td>\n",
       "      <td>0.905313</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.913345</td>\n",
       "      <td>0.916561</td>\n",
       "      <td>0.881003</td>\n",
       "      <td>0.933790</td>\n",
       "      <td>0.934530</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.814791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_micro</th>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.700905</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.676018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.802715</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912670</td>\n",
       "      <td>0.916290</td>\n",
       "      <td>0.881448</td>\n",
       "      <td>0.933937</td>\n",
       "      <td>0.934389</td>\n",
       "      <td>0.927602</td>\n",
       "      <td>0.828507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_weighted</th>\n",
       "      <td>0.947041</td>\n",
       "      <td>0.672963</td>\n",
       "      <td>0.948016</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782418</td>\n",
       "      <td>0.935214</td>\n",
       "      <td>0.801187</td>\n",
       "      <td>0.948110</td>\n",
       "      <td>0.905351</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.913351</td>\n",
       "      <td>0.916598</td>\n",
       "      <td>0.880938</td>\n",
       "      <td>0.933802</td>\n",
       "      <td>0.934506</td>\n",
       "      <td>0.927751</td>\n",
       "      <td>0.814830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>0.192368</td>\n",
       "      <td>0.950227</td>\n",
       "      <td>0.161245</td>\n",
       "      <td>0.900073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833507</td>\n",
       "      <td>0.186199</td>\n",
       "      <td>0.705862</td>\n",
       "      <td>0.172342</td>\n",
       "      <td>0.479872</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.373229</td>\n",
       "      <td>0.421599</td>\n",
       "      <td>0.711661</td>\n",
       "      <td>0.218715</td>\n",
       "      <td>0.207372</td>\n",
       "      <td>0.635263</td>\n",
       "      <td>1.129849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.370789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_macro_recall</th>\n",
       "      <td>0.936459</td>\n",
       "      <td>0.640888</td>\n",
       "      <td>0.937553</td>\n",
       "      <td>0.611456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742047</td>\n",
       "      <td>0.921807</td>\n",
       "      <td>0.763285</td>\n",
       "      <td>0.937547</td>\n",
       "      <td>0.885928</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.895204</td>\n",
       "      <td>0.899515</td>\n",
       "      <td>0.857821</td>\n",
       "      <td>0.920698</td>\n",
       "      <td>0.921299</td>\n",
       "      <td>0.913107</td>\n",
       "      <td>0.794172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.891938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_macro</th>\n",
       "      <td>0.947180</td>\n",
       "      <td>0.715796</td>\n",
       "      <td>0.948258</td>\n",
       "      <td>0.708655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791533</td>\n",
       "      <td>0.935896</td>\n",
       "      <td>0.803343</td>\n",
       "      <td>0.948387</td>\n",
       "      <td>0.906302</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.914840</td>\n",
       "      <td>0.917483</td>\n",
       "      <td>0.882087</td>\n",
       "      <td>0.934038</td>\n",
       "      <td>0.934888</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.835732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_micro</th>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.700905</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.676018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.802715</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912670</td>\n",
       "      <td>0.916290</td>\n",
       "      <td>0.881448</td>\n",
       "      <td>0.933937</td>\n",
       "      <td>0.934389</td>\n",
       "      <td>0.927602</td>\n",
       "      <td>0.828507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_weighted</th>\n",
       "      <td>0.947203</td>\n",
       "      <td>0.715905</td>\n",
       "      <td>0.948270</td>\n",
       "      <td>0.708604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791535</td>\n",
       "      <td>0.935899</td>\n",
       "      <td>0.803290</td>\n",
       "      <td>0.948383</td>\n",
       "      <td>0.906340</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.914851</td>\n",
       "      <td>0.917531</td>\n",
       "      <td>0.882026</td>\n",
       "      <td>0.934039</td>\n",
       "      <td>0.934865</td>\n",
       "      <td>0.928091</td>\n",
       "      <td>0.835755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.910884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_macro</th>\n",
       "      <td>0.947049</td>\n",
       "      <td>0.700740</td>\n",
       "      <td>0.947961</td>\n",
       "      <td>0.676213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785039</td>\n",
       "      <td>0.934839</td>\n",
       "      <td>0.802738</td>\n",
       "      <td>0.947956</td>\n",
       "      <td>0.904940</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912670</td>\n",
       "      <td>0.916263</td>\n",
       "      <td>0.881517</td>\n",
       "      <td>0.933915</td>\n",
       "      <td>0.934416</td>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.828477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_micro</th>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.700905</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.676018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.802715</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912670</td>\n",
       "      <td>0.916290</td>\n",
       "      <td>0.881448</td>\n",
       "      <td>0.933937</td>\n",
       "      <td>0.934389</td>\n",
       "      <td>0.927602</td>\n",
       "      <td>0.828507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_weighted</th>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.700905</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.676018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785068</td>\n",
       "      <td>0.934842</td>\n",
       "      <td>0.802715</td>\n",
       "      <td>0.947964</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912670</td>\n",
       "      <td>0.916290</td>\n",
       "      <td>0.881448</td>\n",
       "      <td>0.933937</td>\n",
       "      <td>0.934389</td>\n",
       "      <td>0.927602</td>\n",
       "      <td>0.828507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_accuracy</th>\n",
       "      <td>0.947069</td>\n",
       "      <td>0.701070</td>\n",
       "      <td>0.947967</td>\n",
       "      <td>0.675823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785097</td>\n",
       "      <td>0.934844</td>\n",
       "      <td>0.802692</td>\n",
       "      <td>0.947972</td>\n",
       "      <td>0.905014</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912669</td>\n",
       "      <td>0.916316</td>\n",
       "      <td>0.881379</td>\n",
       "      <td>0.933958</td>\n",
       "      <td>0.934363</td>\n",
       "      <td>0.927615</td>\n",
       "      <td>0.828537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0         1         2         3    4   \\\n",
       "AUC_macro                         0.994984  0.928042  0.996208  0.896381  NaN   \n",
       "AUC_micro                         0.995817  0.936663  0.996712  0.913619  NaN   \n",
       "AUC_weighted                      0.994985  0.928087  0.996208  0.896389  NaN   \n",
       "accuracy                          0.947059  0.700905  0.947964  0.676018  NaN   \n",
       "accuracy_max                      0.947059  0.700905  0.947964  0.676018  0.0   \n",
       "average_precision_score_macro     0.982230  0.807306  0.984755  0.692530  NaN   \n",
       "average_precision_score_micro     0.985318  0.802095  0.987126  0.745719  NaN   \n",
       "average_precision_score_weighted  0.982235  0.807421  0.984759  0.692512  NaN   \n",
       "balanced_accuracy                 0.947049  0.700740  0.947961  0.676213  NaN   \n",
       "f1_score_macro                    0.947024  0.672795  0.948008  0.633855  NaN   \n",
       "f1_score_micro                    0.947059  0.700905  0.947964  0.676018  NaN   \n",
       "f1_score_weighted                 0.947041  0.672963  0.948016  0.633665  NaN   \n",
       "log_loss                          0.192368  0.950227  0.161245  0.900073  NaN   \n",
       "norm_macro_recall                 0.936459  0.640888  0.937553  0.611456  NaN   \n",
       "precision_score_macro             0.947180  0.715796  0.948258  0.708655  NaN   \n",
       "precision_score_micro             0.947059  0.700905  0.947964  0.676018  NaN   \n",
       "precision_score_weighted          0.947203  0.715905  0.948270  0.708604  NaN   \n",
       "recall_score_macro                0.947049  0.700740  0.947961  0.676213  NaN   \n",
       "recall_score_micro                0.947059  0.700905  0.947964  0.676018  NaN   \n",
       "recall_score_weighted             0.947059  0.700905  0.947964  0.676018  NaN   \n",
       "weighted_accuracy                 0.947069  0.701070  0.947967  0.675823  NaN   \n",
       "\n",
       "                                        5         6         7         8   \\\n",
       "AUC_macro                         0.953435  0.995235  0.967551  0.995921   \n",
       "AUC_micro                         0.956000  0.995898  0.968449  0.996541   \n",
       "AUC_weighted                      0.953427  0.995235  0.967548  0.995922   \n",
       "accuracy                          0.785068  0.934842  0.802715  0.947964   \n",
       "accuracy_max                      0.947059  0.947964  0.947964  0.947964   \n",
       "average_precision_score_macro     0.853102  0.979521  0.884399  0.983521   \n",
       "average_precision_score_micro     0.851408  0.983464  0.895054  0.986216   \n",
       "average_precision_score_weighted  0.853077  0.979524  0.884371  0.983526   \n",
       "balanced_accuracy                 0.785039  0.934839  0.802738  0.947956   \n",
       "f1_score_macro                    0.782397  0.935211  0.801225  0.948108   \n",
       "f1_score_micro                    0.785068  0.934842  0.802715  0.947964   \n",
       "f1_score_weighted                 0.782418  0.935214  0.801187  0.948110   \n",
       "log_loss                          0.833507  0.186199  0.705862  0.172342   \n",
       "norm_macro_recall                 0.742047  0.921807  0.763285  0.937547   \n",
       "precision_score_macro             0.791533  0.935896  0.803343  0.948387   \n",
       "precision_score_micro             0.785068  0.934842  0.802715  0.947964   \n",
       "precision_score_weighted          0.791535  0.935899  0.803290  0.948383   \n",
       "recall_score_macro                0.785039  0.934839  0.802738  0.947956   \n",
       "recall_score_micro                0.785068  0.934842  0.802715  0.947964   \n",
       "recall_score_weighted             0.785068  0.934842  0.802715  0.947964   \n",
       "weighted_accuracy                 0.785097  0.934844  0.802692  0.947972   \n",
       "\n",
       "                                        9     ...     15        16        17  \\\n",
       "AUC_macro                         0.989519    ...    NaN  0.990245  0.991259   \n",
       "AUC_micro                         0.990898    ...    NaN  0.991174  0.991835   \n",
       "AUC_weighted                      0.989524    ...    NaN  0.990248  0.991262   \n",
       "accuracy                          0.904977    ...    NaN  0.912670  0.916290   \n",
       "accuracy_max                      0.947964    ...    NaN  0.947964  0.947964   \n",
       "average_precision_score_macro     0.959627    ...    NaN  0.961124  0.964038   \n",
       "average_precision_score_micro     0.967261    ...    NaN  0.967948  0.969875   \n",
       "average_precision_score_weighted  0.959650    ...    NaN  0.961136  0.964058   \n",
       "balanced_accuracy                 0.904940    ...    NaN  0.912670  0.916263   \n",
       "f1_score_macro                    0.905313    ...    NaN  0.913345  0.916561   \n",
       "f1_score_micro                    0.904977    ...    NaN  0.912670  0.916290   \n",
       "f1_score_weighted                 0.905351    ...    NaN  0.913351  0.916598   \n",
       "log_loss                          0.479872    ...    NaN  0.373229  0.421599   \n",
       "norm_macro_recall                 0.885928    ...    NaN  0.895204  0.899515   \n",
       "precision_score_macro             0.906302    ...    NaN  0.914840  0.917483   \n",
       "precision_score_micro             0.904977    ...    NaN  0.912670  0.916290   \n",
       "precision_score_weighted          0.906340    ...    NaN  0.914851  0.917531   \n",
       "recall_score_macro                0.904940    ...    NaN  0.912670  0.916263   \n",
       "recall_score_micro                0.904977    ...    NaN  0.912670  0.916290   \n",
       "recall_score_weighted             0.904977    ...    NaN  0.912670  0.916290   \n",
       "weighted_accuracy                 0.905014    ...    NaN  0.912669  0.916316   \n",
       "\n",
       "                                        18        19        20        21  \\\n",
       "AUC_macro                         0.984884  0.993205  0.993959  0.992093   \n",
       "AUC_micro                         0.986213  0.993833  0.994692  0.991800   \n",
       "AUC_weighted                      0.984875  0.993207  0.993957  0.992095   \n",
       "accuracy                          0.881448  0.933937  0.934389  0.927602   \n",
       "accuracy_max                      0.947964  0.947964  0.959276  0.959276   \n",
       "average_precision_score_macro     0.939151  0.973369  0.976778  0.968370   \n",
       "average_precision_score_micro     0.949393  0.977267  0.981050  0.971437   \n",
       "average_precision_score_weighted  0.939100  0.973372  0.976763  0.968378   \n",
       "balanced_accuracy                 0.881517  0.933915  0.934416  0.927589   \n",
       "f1_score_macro                    0.881003  0.933790  0.934530  0.927734   \n",
       "f1_score_micro                    0.881448  0.933937  0.934389  0.927602   \n",
       "f1_score_weighted                 0.880938  0.933802  0.934506  0.927751   \n",
       "log_loss                          0.711661  0.218715  0.207372  0.635263   \n",
       "norm_macro_recall                 0.857821  0.920698  0.921299  0.913107   \n",
       "precision_score_macro             0.882087  0.934038  0.934888  0.928069   \n",
       "precision_score_micro             0.881448  0.933937  0.934389  0.927602   \n",
       "precision_score_weighted          0.882026  0.934039  0.934865  0.928091   \n",
       "recall_score_macro                0.881517  0.933915  0.934416  0.927589   \n",
       "recall_score_micro                0.881448  0.933937  0.934389  0.927602   \n",
       "recall_score_weighted             0.881448  0.933937  0.934389  0.927602   \n",
       "weighted_accuracy                 0.881379  0.933958  0.934363  0.927615   \n",
       "\n",
       "                                        22  23        24  \n",
       "AUC_macro                         0.977915 NaN  0.990631  \n",
       "AUC_micro                         0.977442 NaN  0.991687  \n",
       "AUC_weighted                      0.977914 NaN  0.990634  \n",
       "accuracy                          0.828507 NaN  0.909955  \n",
       "accuracy_max                      0.959276 NaN  0.959276  \n",
       "average_precision_score_macro     0.913278 NaN  0.961575  \n",
       "average_precision_score_micro     0.914418 NaN  0.968285  \n",
       "average_precision_score_weighted  0.913286 NaN  0.961590  \n",
       "balanced_accuracy                 0.828477 NaN  0.909948  \n",
       "f1_score_macro                    0.814791 NaN  0.910211  \n",
       "f1_score_micro                    0.828507 NaN  0.909955  \n",
       "f1_score_weighted                 0.814830 NaN  0.910223  \n",
       "log_loss                          1.129849 NaN  0.370789  \n",
       "norm_macro_recall                 0.794172 NaN  0.891938  \n",
       "precision_score_macro             0.835732 NaN  0.910867  \n",
       "precision_score_micro             0.828507 NaN  0.909955  \n",
       "precision_score_weighted          0.835755 NaN  0.910884  \n",
       "recall_score_macro                0.828477 NaN  0.909948  \n",
       "recall_score_micro                0.828507 NaN  0.909955  \n",
       "recall_score_weighted             0.828507 NaN  0.909955  \n",
       "weighted_accuracy                 0.828537 NaN  0.909961  \n",
       "\n",
       "[21 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "children = list(run.get_children())\n",
    "metricslist = {}\n",
    "for child in children:\n",
    "    properties = child.get_properties()\n",
    "    metrics = {k: v for k, v in child.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waiting until the run finishes\n",
    "\n",
    "`wait_for_complettion` method will block till the run finishes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "***********************************************************************************************\n",
      "\n",
      " ITERATION     PIPELINE                               DURATION                METRIC      BEST\n",
      "         0     StandardScalerWrapper LogisticRegressio367                      0.947     0.947\n",
      "         1     MaxAbsScaler RandomForestClassifier    992                      0.701     0.947\n",
      "         2     MaxAbsScaler LightGBMClassifier        208                      0.948     0.948\n",
      "         3     StandardScalerWrapper RandomForestClass474                      0.676     0.948\n",
      "         4     MinMaxScaler RandomForestClassifier    0                          nan     0.948\n",
      "         5     MaxAbsScaler RandomForestClassifier    229                      0.785     0.948\n",
      "         6     StandardScalerWrapper LightGBMClassifie39                       0.935     0.948\n",
      "         7     MaxAbsScaler RandomForestClassifier    23                       0.803     0.948\n",
      "         8     StandardScalerWrapper LogisticRegressio364                      0.948     0.948\n",
      "         9     MaxAbsScaler LightGBMClassifier        17                       0.905     0.948\n",
      "        10     StandardScalerWrapper SVCWrapper       1022                     0.959     0.959\n",
      "        11     SparseNormalizer LightGBMClassifier    468                      0.939     0.959\n",
      "        12     SparseNormalizer LightGBMClassifier    57                       0.925     0.959\n",
      "        13     RobustScaler LightGBMClassifier        98                       0.940     0.959\n",
      "        14     StandardScalerWrapper LogisticRegressio24                       0.943     0.959\n",
      "        16     StandardScalerWrapper LightGBMClassifie66                       0.913     0.959\n",
      "        17     StandardScalerWrapper LightGBMClassifie103                      0.916     0.959\n",
      "        18     MaxAbsScaler ExtraTreesClassifier      35                       0.881     0.959\n",
      "        19     RobustScaler LightGBMClassifier        176                      0.934     0.959\n",
      "        20     MaxAbsScaler LightGBMClassifier        69                       0.934     0.959\n",
      "        21     SparseNormalizer LogisticRegression    84                       0.928     0.959\n",
      "        22     StandardScalerWrapper RandomForestClass35                       0.829     0.959\n",
      "        24     StandardScalerWrapper LightGBMClassifie56                       0.910     0.959\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab',\n",
       " 'target': 'batchaicls',\n",
       " 'status': 'Running',\n",
       " 'startTimeUtc': '2018-11-20T15:52:17.503812Z',\n",
       " 'properties': {'num_iterations': '25',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'accuracy',\n",
       "  'train_split': '0',\n",
       "  'max_time_seconds': '1800',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': None,\n",
       "  'target': 'batchaicls',\n",
       "  'RawAMLSettingsString': \"{'name': 'aerial-automatedML', 'path': './script', 'subscription_id': '952a710c-8d9c-40c1-9fec-f752138cc0b3', 'resource_group': 'jkamllab', 'workspace_name': 'jkamllab', 'iterations': 25, 'primary_metric': 'accuracy', 'data_script': './script/get_data.py', 'compute_target': 'batchaicls', 'task_type': 'classification', 'validation_size': 0.0, 'n_cross_validations': None, 'y_min': None, 'y_max': None, 'num_classes': 6, 'preprocess': False, 'lag_length': 0, 'max_cores_per_iteration': 1, 'concurrent_iterations': 5, 'max_time_sec': 1800, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'exit_time_sec': None, 'exit_score': 0.96, 'blacklist_algos': ['KNeighborsClassifier', 'LinearSVMWrapper', 'NBWrapper', 'BernoulliNB', 'GradientBoostingClassifier', 'SGDClassifierWrapper'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'telemetry_verbosity': 'NOTSET', 'send_telemetry': False, 'metrics': None, 'enable_ensembling': False, 'ensemble_iterations': 1, 'enable_tf': False, 'metric_operation': 'maximize'}\",\n",
       "  'AMLSettingsJsonString': '{\"name\": \"aerial-automatedML\", \"path\": \"./script\", \"subscription_id\": \"952a710c-8d9c-40c1-9fec-f752138cc0b3\", \"resource_group\": \"jkamllab\", \"workspace_name\": \"jkamllab\", \"iterations\": 25, \"primary_metric\": \"accuracy\", \"data_script\": \"./script/get_data.py\", \"compute_target\": \"batchaicls\", \"task_type\": \"classification\", \"validation_size\": 0.0, \"n_cross_validations\": null, \"y_min\": null, \"y_max\": null, \"num_classes\": 6, \"preprocess\": false, \"lag_length\": 0, \"max_cores_per_iteration\": 1, \"concurrent_iterations\": 5, \"max_time_sec\": 1800, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"exit_time_sec\": null, \"exit_score\": 0.96, \"blacklist_algos\": [\"KNeighborsClassifier\", \"LinearSVMWrapper\", \"NBWrapper\", \"BernoulliNB\", \"GradientBoostingClassifier\", \"SGDClassifierWrapper\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"telemetry_verbosity\": \"NOTSET\", \"send_telemetry\": false, \"metrics\": null, \"enable_ensembling\": false, \"ensemble_iterations\": 1, \"enable_tf\": false, \"metric_operation\": \"maximize\"}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'SetupRunId': 'AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab_setup',\n",
       "  'snapshotId': '68569f84-40d9-4c8b-a618-4fc69d48c728',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"dataset_classes\": 6, \"dataset_features\": 2048, \"dataset_samples\": 19882, \"is_sparse\": false}'},\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait until the run finishes.\n",
    "run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the best model\n",
    "\n",
    "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*.\n",
    "\n",
    "#### Best model based on the primary metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: aerial-automatedML,\n",
      "Id: AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab_10,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fcea81f1d68>), ('SVCWrapper', SVCWrapper(C=4714.8663634573895, class_weight=None, kernel='poly',\n",
      "      probability=True, random_state=None))])\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model based on any metric\n",
    "You can also retrieve the best model based on an arbitrary metric. For example, we will retrieve the model with the highest AUC value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: aerial-automatedML,\n",
      "Id: AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab_10,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fce9467a9e8>), ('SVCWrapper', SVCWrapper(C=4714.8663634573895, class_weight=None, kernel='poly',\n",
      "      probability=True, random_state=None))])\n"
     ]
    }
   ],
   "source": [
    "lookup_metric = \"AUC_weighted\"\n",
    "best_run_auc, fitted_model_best_auc = run.get_output(metric = lookup_metric)\n",
    "print(best_run_auc)\n",
    "print(fitted_model_best_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model from a specific iteration\n",
    "Show the run and the model from the third iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: aerial-automatedML,\n",
      "Id: AutoML_ac5fd8f3-7e2d-482b-ada1-b2f3f270a5ab_3,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fcea848ebe0>), ('RandomForestClassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "    ...imators=100, n_jobs=1,\n",
      "            oob_score=True, random_state=None, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "iteration = 3\n",
    "third_run, third_model = run.get_output(iteration=iteration)\n",
    "print(third_run)\n",
    "print(third_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the best model\n",
    "\n",
    "You can use `AutoMLRun` to register the trained model with AML Model Registry.\n",
    "\n",
    "If neither `metric` nor `iteration` are specified in the `register_model` call, the iteration with the best primary metric is registered.\n",
    "\n",
    "We are going to add two properties to the registration:\n",
    "- FriendlyName. We will use this property to retrieve the model in the next lab\n",
    "- RunID. This property will store the ID of the run that created the model. We will use it to retrieve runtime dependencies in the next lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model AutoMLac5fd8f37best\n",
      "Model properties add operation complete.\n"
     ]
    }
   ],
   "source": [
    "description = 'Aerial Classifier Model - Best Accuracy'\n",
    "model_name = 'AerialClassifier'\n",
    "\n",
    "model = run.register_model(description=description, tags=tags)\n",
    "properties = {\"FriendlyName\": \"Lab3BestModel\", \"RunID\": run.id}\n",
    "model.add_properties(properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "The model is ready for deployment. In the next lab you will deploy the model to Azure Container Instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "Before you move to the next step, you can delete the BAI cluster. We will not need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bai_compute_target.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
