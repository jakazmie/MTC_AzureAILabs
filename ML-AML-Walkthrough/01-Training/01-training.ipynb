{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Training a Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lab is to demonstarte how to orchestrate machine learning **training** with *Azure Machine Learning service*. \n",
    "\n",
    "To keep the focus of the lab on **workflow orchestration** rather then on idiosyncrasies of a domain problem, we have chosen a relatively simple machine learning scenario.\n",
    "\n",
    "During the lab you will learn how to:\n",
    "- Track training iterations a.k.a *Runs* in *Azure ML Experiment*\n",
    "- Execute training scripts on powerful, cloud compute resources - *Azure ML Compute*.\n",
    "- Register the best performing model with *Azure ML Model Registry*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "You will train a binary classification model to predict propensity to purchase. The dataset comes from the UCI Machine Learning repository, and it is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The goal of the model is to help with campaign planning by predicting which clients will respond positively to marketing phone calls. \n",
    "\n",
    "\n",
    "## Connect AML workspace\n",
    "\n",
    "Check the version of AML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Verify AML SDK Installed\n",
    "\n",
    "import azureml.core\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/MTC_AzureAILabs/ML-AML-Walkthrough/aml_config/config.json\n",
      "jkamlworkshop\n",
      "jkamlworkshop\n",
      "southcentralus\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Connect to workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "### Download the dataset\n",
    "The dataset can be downloaded from a public Azure Blob Storage container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget -O ../datasets/banking.csv https://azureailabs.blob.core.windows.net/banking/banking.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['banking.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = '../datasets'\n",
    "filename = 'banking.csv'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "downloadCommand = 'wget -O ''{0}/{1}'' ''https://azureailabs.blob.core.windows.net/banking/{1}'''.format(folder, filename)\n",
    "print(downloadCommand)\n",
    "os.system(downloadCommand)\n",
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      "age               41188 non-null int64\n",
      "job               41188 non-null object\n",
      "marital           41188 non-null object\n",
      "education         41188 non-null object\n",
      "default           41188 non-null object\n",
      "housing           41188 non-null object\n",
      "loan              41188 non-null object\n",
      "contact           41188 non-null object\n",
      "month             41188 non-null object\n",
      "day_of_week       41188 non-null object\n",
      "duration          41188 non-null int64\n",
      "campaign          41188 non-null int64\n",
      "pdays             41188 non-null int64\n",
      "previous          41188 non-null int64\n",
      "poutcome          41188 non-null object\n",
      "emp_var_rate      41188 non-null float64\n",
      "cons_price_idx    41188 non-null float64\n",
      "cons_conf_idx     41188 non-null float64\n",
      "euribor3m         41188 non-null float64\n",
      "nr_employed       41188 non-null float64\n",
      "y                 41188 non-null int64\n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 6.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education  default housing loan  \\\n",
       "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
       "1   53   technician  married            unknown       no      no   no   \n",
       "2   28   management   single  university.degree       no     yes   no   \n",
       "3   39     services  married        high.school       no      no   no   \n",
       "4   55      retired  married           basic.4y       no     yes   no   \n",
       "\n",
       "    contact month day_of_week ...  campaign  pdays  previous     poutcome  \\\n",
       "0  cellular   aug         thu ...         1    999         0  nonexistent   \n",
       "1  cellular   nov         fri ...         1    999         0  nonexistent   \n",
       "2  cellular   jun         thu ...         3      6         2      success   \n",
       "3  cellular   apr         fri ...         2    999         0  nonexistent   \n",
       "4  cellular   aug         fri ...         1      3         1      success   \n",
       "\n",
       "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
       "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
       "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
       "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
       "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder = '../datasets'\n",
    "filename = 'banking.csv'\n",
    "pathname = os.path.join(folder, filename)\n",
    "df_raw = pd.read_csv(pathname, delimiter=',')\n",
    "print(df_raw.info())\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset combines the information about the bank's customers with the results of previous campaigns and key economic indicators. It includes 41,188 records and 21 fields. The columns are a mix of numeric and categorical data types.\n",
    "\n",
    "The `y` column indicates whether the customer subscribed to a term deposit. This is our `target` variable or `label`. The goal of the model is to predict this column on new examples.\n",
    "\n",
    "Some information that exists in the historical dataset will not be available when planning a new campaign. \n",
    "\n",
    "Please refer to [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/bank+marketing) for more information. \n",
    "\n",
    "We will use the following features for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>aug</td>\n",
       "      <td>1</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>unknown</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>nov</td>\n",
       "      <td>1</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>single</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>jun</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>high.school</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>apr</td>\n",
       "      <td>2</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>aug</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job          education  marital housing loan month  campaign  \\\n",
       "0   44  blue-collar           basic.4y  married     yes   no   aug         1   \n",
       "1   53   technician            unknown  married      no   no   nov         1   \n",
       "2   28   management  university.degree   single     yes   no   jun         3   \n",
       "3   39     services        high.school  married      no   no   apr         2   \n",
       "4   55      retired           basic.4y  married     yes   no   aug         1   \n",
       "\n",
       "      poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  \\\n",
       "0  nonexistent           1.4          93.444          -36.1      4.963   \n",
       "1  nonexistent          -0.1          93.200          -42.0      4.021   \n",
       "2      success          -1.7          94.055          -39.8      0.729   \n",
       "3  nonexistent          -1.8          93.075          -47.1      1.405   \n",
       "4      success          -2.9          92.201          -31.4      0.869   \n",
       "\n",
       "   nr_employed  y  \n",
       "0       5228.1  0  \n",
       "1       5195.8  0  \n",
       "2       4991.6  1  \n",
       "3       5099.1  0  \n",
       "4       5076.2  1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [\n",
    "                   # Demographic\n",
    "                   'age', \n",
    "                   'job', \n",
    "                   'education', \n",
    "                   'marital',  \n",
    "                   'housing', \n",
    "                   'loan', \n",
    "                   # Previous campaigns\n",
    "                   'month',\n",
    "                   'campaign',\n",
    "                   'poutcome',\n",
    "                   # Economic indicators\n",
    "                   'emp_var_rate',\n",
    "                   'cons_price_idx',\n",
    "                   'cons_conf_idx',\n",
    "                   'euribor3m',\n",
    "                   'nr_employed']\n",
    "\n",
    "df_raw = df_raw[feature_columns + ['y']]\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-learn` estimators expect continuous input. Some of the features in the dataset are categorical and encoded as strings. We will use *dummy* encoding to convert categorical features to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df_raw, drop_first=True).astype(dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reserve a portion of data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(\n",
    "   df, \n",
    "   test_size = 0.2,\n",
    "   stratify = df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the class distribution in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd7c133c128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(train.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is very imbalanced. We will need to address this when configuring training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "In this section of the lab you will train a binary classification model.\n",
    "\n",
    "You will first run training on a local workstation and use Azure Machine Learning Experiment to track training progress. In the following step, you will use Azure Machine Learning Compute to run  training on more powerful cloud compute resources.\n",
    "\n",
    "In the Azure Machine Learning service, you can track training artifacts (alogorithm settings, performance metrics, logs, serialized models, etc.)  created during training iterations a.k.a *Runs* using Azure ML *Experiment*. To do that you must instrument your code with logging statements and trigger logging when you submit the *Run*. The following are two ways to trigger the run submission:\n",
    "\n",
    "- Start an interactive logging session in the specified *Experiment*. As you execute logging statements, any artifacts that are logged during the session are added to the run record in the experiment. We will use this approach when training the model on the local compute.\n",
    "\n",
    "- Add logging functions to your training script and trigger logging when submitting the script to run on a given compute resource. With this option, you can add monitoring code to be notified of completion or to get a visual widget to monitor. We will use this approach when training on a remote Azure Machine Learning Compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training pipeline\n",
    "\n",
    "We are going to train a binomial *LogisticRegression* regression model. *LogisticRegression* exposes a number of tuneable hyperparameters. Argueable, the most important setting is the inverse of regularization strength **C** . For the sake of simplicity, we will focus on tuning this hyperparameter when training our model. We will use *GridSearchCV* to automate the hyperparameter tuning process. \n",
    "\n",
    "The business goal of our model is to identify customers with high propencity to buy. As such, we want to minimize the number of false negatives - customers who were wrongly identified as ones with low propencity to buy. We want the model with a high *recall*.\n",
    "\n",
    "Since the dataset is imbalanced we will set *class_weight* parameter to `balanced` to automatically adjust weights inversely proportional to class frequencies in in the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=300,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'lr__C': [0.1, 0.5, 1, 2, 5]}, pre_dispatch='2*n_jobs',\n",
       "       refit='recall', return_train_score=False,\n",
       "       scoring=['recall', 'accuracy'], verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Create logistic regression estimater\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=300, class_weight='balanced')\n",
    "\n",
    "# Logistic regression requires feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a training pipeline\n",
    "pipeline = Pipeline(steps=[('scaler', scaler),\n",
    "                           ('lr', lr)])\n",
    "\n",
    "# Configure grid search\n",
    "param_grid = {'lr__C': [0.1, 0.5, 1, 2, 5]}\n",
    "clf = GridSearchCV(pipeline,\n",
    "                   param_grid, \n",
    "                   cv=5, \n",
    "                   scoring=['recall', 'accuracy'],\n",
    "                   refit = 'recall',\n",
    "                   return_train_score = False\n",
    "                   )\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training on a local compute\n",
    "\n",
    "Start training on a local workstation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=300,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'lr__C': [0.1, 0.5, 1, 2, 5]}, pre_dispatch='2*n_jobs',\n",
       "       refit='recall', return_train_score=False,\n",
       "       scoring=['recall', 'accuracy'], verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop('y', axis=1)\n",
    "y = train.y\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.15895162, 0.18452621, 0.18102312, 0.18209901, 0.17724657]),\n",
       " 'std_fit_time': array([0.01009018, 0.02867489, 0.01698967, 0.00476917, 0.01307957]),\n",
       " 'mean_score_time': array([0.00663142, 0.00694442, 0.00753961, 0.00658607, 0.00654235]),\n",
       " 'std_score_time': array([0.00020716, 0.00086963, 0.00213714, 0.00011498, 0.00029649]),\n",
       " 'param_lr__C': masked_array(data=[0.1, 0.5, 1, 2, 5],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'lr__C': 0.1},\n",
       "  {'lr__C': 0.5},\n",
       "  {'lr__C': 1},\n",
       "  {'lr__C': 2},\n",
       "  {'lr__C': 5}],\n",
       " 'split0_test_recall': array([0.59219381, 0.59219381, 0.59219381, 0.59219381, 0.59219381]),\n",
       " 'split1_test_recall': array([0.60430686, 0.60430686, 0.60430686, 0.60430686, 0.60430686]),\n",
       " 'split2_test_recall': array([0.66846361, 0.6671159 , 0.6671159 , 0.6671159 , 0.6671159 ]),\n",
       " 'split3_test_recall': array([0.6361186 , 0.63342318, 0.63342318, 0.63342318, 0.63342318]),\n",
       " 'split4_test_recall': array([0.6212938 , 0.61994609, 0.61994609, 0.61994609, 0.61994609]),\n",
       " 'mean_test_recall': array([0.62447349, 0.62339544, 0.62339544, 0.62339544, 0.62339544]),\n",
       " 'std_test_recall': array([0.0265696 , 0.02593081, 0.02593081, 0.02593081, 0.02593081]),\n",
       " 'rank_test_recall': array([1, 2, 2, 2, 2], dtype=int32),\n",
       " 'split0_test_accuracy': array([0.83477469, 0.83492641, 0.83492641, 0.83492641, 0.83492641]),\n",
       " 'split1_test_accuracy': array([0.82248521, 0.82385071, 0.82415415, 0.82430587, 0.82445759]),\n",
       " 'split2_test_accuracy': array([0.82852807, 0.82959029, 0.82959029, 0.82959029, 0.82974203]),\n",
       " 'split3_test_accuracy': array([0.83715283, 0.8377599 , 0.83791167, 0.83791167, 0.83791167]),\n",
       " 'split4_test_accuracy': array([0.83259979, 0.83244802, 0.83244802, 0.83244802, 0.83259979]),\n",
       " 'mean_test_accuracy': array([0.83110774, 0.83171472, 0.83180577, 0.83183612, 0.83192716]),\n",
       " 'std_test_accuracy': array([0.0051619 , 0.00476987, 0.00470942, 0.00466025, 0.00460078]),\n",
       " 'rank_test_accuracy': array([5, 4, 3, 2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display performance metrics for each value of **C**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: {'lr__C': 0.1}, accuracy: 0.8311077389984826, recall: 0.6244734881350328\n",
      "C: {'lr__C': 0.5}, accuracy: 0.8317147192716237, recall: 0.6233954437240368\n",
      "C: {'lr__C': 1}, accuracy: 0.8318057663125948, recall: 0.6233954437240368\n",
      "C: {'lr__C': 2}, accuracy: 0.8318361153262519, recall: 0.6233954437240368\n",
      "C: {'lr__C': 5}, accuracy: 0.8319271623672231, recall: 0.6233954437240368\n"
     ]
    }
   ],
   "source": [
    "for C, accuracy, recall in zip(clf.cv_results_['params'], clf.cv_results_['mean_test_accuracy'], clf.cv_results_['mean_test_recall']):\n",
    "    print(\"C: {}, accuracy: {}, recall: {}\".format(C, accuracy, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the training results in Azure Machine Learning Experiment\n",
    "\n",
    "Create an *Experiment* to track run records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "exp = Experiment(ws, \"propensity_to_buy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used *GridSearchCV* to train multiple models with different setting for **C** we want to reflect this approach in a run record. The natural way is to create a hierarcical run record structure mapping directly to our grid search training regime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing C: 0.1 and accuracy: 0.8311077389984826 and recall: 0.6244734881350328 in Run object\n",
      "Storing C: 0.5 and accuracy: 0.8317147192716237 and recall: 0.6233954437240368 in Run object\n",
      "Storing C: 1 and accuracy: 0.8318057663125948 and recall: 0.6233954437240368 in Run object\n",
      "Storing C: 2 and accuracy: 0.8318361153262519 and recall: 0.6233954437240368 in Run object\n",
      "Storing C: 5 and accuracy: 0.8319271623672231 and recall: 0.6233954437240368 in Run object\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.run import Run\n",
    "\n",
    "# Create a root run\n",
    "root_run = exp.start_logging()\n",
    "\n",
    "# Retrieve training results from GridSearchCV object and store them in child runs of the root run\n",
    "for C, accuracy, recall in zip(clf.cv_results_['params'], clf.cv_results_['mean_test_accuracy'], clf.cv_results_['mean_test_recall']):\n",
    "    run = root_run.child_run(\"Run with C set to {}\".format(C))\n",
    "    run.log(\"C\", C['lr__C'])\n",
    "    run.log(\"Accuracy\", accuracy)\n",
    "    run.log(\"Recall\", recall)\n",
    "    run.complete()\n",
    "    print(\"Storing C: {} and accuracy: {} and recall: {} in Run object\".format(C['lr__C'], accuracy, recall))\n",
    "    \n",
    "# Close the parent run in the experiment\n",
    "root_run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have captured history for various runs, you can review the runs. You could use the Azure Portal for this. You can also use the AML SDK to query the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': '2d966521-d85a-4a71-ba2f-10bd85fe2f25', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T00:00:06.49753Z', 'endTimeUtc': '2019-01-05T00:00:06.856446Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 5, 'Accuracy': 0.8319271623672231, 'Recall': 0.6233954437240368}\n",
      "------------------------------------------------------------\n",
      "{'runId': 'eafd86ce-f3ed-4d75-bab8-c59318776776', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T00:00:05.612279Z', 'endTimeUtc': '2019-01-05T00:00:06.04868Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 2, 'Accuracy': 0.8318361153262519, 'Recall': 0.6233954437240368}\n",
      "------------------------------------------------------------\n",
      "{'runId': 'bd8a3c38-526a-4a61-825d-ce13939a5d93', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T00:00:04.483448Z', 'endTimeUtc': '2019-01-05T00:00:04.854858Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 1, 'Accuracy': 0.8318057663125948, 'Recall': 0.6233954437240368}\n",
      "------------------------------------------------------------\n",
      "{'runId': '1ac936d2-5dff-4b92-b6ba-b69d10b2f830', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T00:00:03.741497Z', 'endTimeUtc': '2019-01-05T00:00:04.117797Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 0.5, 'Accuracy': 0.8317147192716237, 'Recall': 0.6233954437240368}\n",
      "------------------------------------------------------------\n",
      "{'runId': 'ae29c451-cea5-4ec8-865b-f68e26954ae3', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T00:00:02.930295Z', 'endTimeUtc': '2019-01-05T00:00:03.346579Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 0.1, 'Accuracy': 0.8311077389984826, 'Recall': 0.6244734881350328}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List all child runs\n",
    "runs = [r for r in root_run.get_children()]\n",
    "\n",
    "for run in runs:\n",
    "    print(run.get_details())\n",
    "    print(run.get_metrics())\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train remotely using Azure ML Compute\n",
    "\n",
    "Up until now, all of your training was executed locally on the same machine running Jupyter. Now you will execute the same logic targeting a remote Azure ML Compute, which you will provision from code.\n",
    "\n",
    "### Provision Azure ML Compute Cluster\n",
    "\n",
    "We will provision an autoscale Azure ML Computer Cluster. In this lab we will only use a single node on the cluster. In the following labs we will multiple nodes on the cluster to run parallel model selection and hyper parameter tuning jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating\n",
      "Succeeded.................\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-01-05T00:10:11.990000+00:00', 'creationTime': '2019-01-05T00:07:58.151689+00:00', 'currentNodeCount': 1, 'errors': None, 'modifiedTime': '2019-01-05T00:08:36.633395+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 1, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 3, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 1, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_DS11_V2'}\n"
     ]
    }
   ],
   "source": [
    "# Create an Azure ML Compute cluster\n",
    "\n",
    "# Create Azure ML cluster\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpu-cluster\"\n",
    "cluster_min_nodes = 1\n",
    "cluster_max_nodes = 3\n",
    "vm_size = \"STANDARD_DS11_V2\"\n",
    "\n",
    "if cluster_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[cluster_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found existing compute target, using this compute target instead of creating:  ' + cluster_name)\n",
    "    else:\n",
    "        print(\"Error: A compute target with name \",cluster_name,\" was found, but it is not of type AmlCompute.\")\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, \n",
    "                                                                min_nodes = cluster_min_nodes, \n",
    "                                                                max_nodes = cluster_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your cluster ready, you need to upload the training data to the default DataStore for your AML Workspace (which uses Azure Storage). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob jkamlworstoragebvcqonoz azureml-blobstore-77114569-d741-41ff-81b0-43cf36590b03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_80479c3fd7944b88bbff63208482eda0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the dataset to the DataStore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "ds.upload(src_dir='../datasets', target_path='banking', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will need to create a training script that is similar to the code you have executed locally to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "# let user feed in 2 parameters, the location of the data files (from datastore), and the training set percentage to use\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--C', type=float, dest='C', default=1, help='regularization')\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_folder = os.path.join(args.data_folder, 'used_cars')\n",
    "print('Data folder:', data_folder)\n",
    "data_csv_path = os.path.join(data_folder, 'UsedCars_Clean.csv')\n",
    "print('Path to CSV file dataset:' + data_csv_path)\n",
    "\n",
    "# Load the data\n",
    "#df = pd.read_csv('UsedCars_Clean.csv', delimiter=',')\n",
    "df = pd.read_csv(data_csv_path)\n",
    "df['Affordable'] = np.where(df['Price']<12000, 1, 0)\n",
    "df_affordability = df[[\"Age\",\"KM\", \"Affordable\"]]\n",
    "\n",
    "\n",
    "# Now experiment with different training subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "full_X = df_affordability[[\"Age\", \"KM\"]]\n",
    "full_Y = df_affordability[[\"Affordable\"]]\n",
    "\n",
    "def train_eval_model(full_X, full_Y,training_set_percentage, C):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, train_size=training_set_percentage, random_state=42)\n",
    "    \n",
    "    # Flatten labels\n",
    "    train_Y = np.ravel(train_Y)\n",
    "    test_Y = np.ravel(test_Y)\n",
    "    \n",
    "    # Convert to float\n",
    "    train_X = train_X.astype(float)\n",
    "    test_X = test_X.astype(float)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(train_X)\n",
    "    clf = linear_model.LogisticRegression(C=C, solver='lbfgs')\n",
    "    clf.fit(X_scaled, train_Y)\n",
    "\n",
    "    scaled_inputs = scaler.transform(test_X)\n",
    "    predictions = clf.predict(scaled_inputs)\n",
    "    score = accuracy_score(test_Y, predictions)\n",
    "\n",
    "    return (clf, score)\n",
    "\n",
    "# Acquire the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "training_set_percentage = args.training_set_percentage\n",
    "C = args.C\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage, C)\n",
    "print(\"With C={}, model accuracy reached {})\".format(C, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"C\", C)\n",
    "run.log(\"Accuracy\", score)\n",
    "\n",
    "\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an estimator that descrives the configuration of the job that will execute your model training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator\n",
    "#############################\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--training-set-percentage': 0.3,\n",
    "    '--C': 2\n",
    "}\n",
    "\n",
    "est_config = Estimator(source_directory=script_folder,\n",
    "                       script_params=script_params,\n",
    "                       compute_target=compute_target,\n",
    "                       entry_script='train.py',\n",
    "                       conda_packages=['scikit-learn', 'pandas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the job using the submit() method of the Experiment object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Execute the estimator job\n",
    "#####################################\n",
    "\n",
    "# Create new experiment\n",
    "from azureml.core import Experiment\n",
    "experiment_name = \"usedcars_training_amlcompute\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "run = exp.submit(config=est_config)\n",
    "run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the job through Azure Portal or using AML Jupyter Widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for job status\n",
    "run.wait_for_completion(show_output=True)  # value of True will display a verbose, streaming log\n",
    "\n",
    "# Examine the recorded metrics from the run\n",
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "01 model training",
  "notebookId": 863281121960369
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
