{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Training a Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lab is to demonstarte how to use Azure Machine Learning service to orchestrate machine learning **training** workflows. \n",
    "\n",
    "To keep the focus of the lab on **workflow orchestration** rather then on idiosyncrasies of a domain problem, we have chosen a relatively simple machine learning scenario.\n",
    "\n",
    "During the lab you will learn how to:\n",
    "- Track training iterations a.k.a *Runs* in *Azure ML Experiment*\n",
    "- Execute training scripts on remote, cloud compute resources - *Azure ML Compute*.\n",
    "- Register the best performing model with *Azure ML Model Registry*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "You will train a binary classification model to predict propensity to purchase. The dataset comes from the UCI Machine Learning repository, and it is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The goal of the model is to help with campaign planning by predicting which clients will respond positively to marketing phone calls. \n",
    "\n",
    "\n",
    "## Connect AML workspace\n",
    "\n",
    "Check the version of AML SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Verify AML SDK Installed\n",
    "\n",
    "import azureml.core\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/MTC_AzureAILabs/ML-AML-Walkthrough/aml_config/config.json\n",
      "jkamlworkshop\n",
      "jkamlworkshop\n",
      "southcentralus\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# Connect to workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "### Download the dataset\n",
    "The dataset used in the lab can be downloaded from a public Azure Blob Storage container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget -O ../datasets/banking_train.csv https://azureailabs.blob.core.windows.net/banking/banking_train.csv\n",
      "wget -O ../datasets/banking_test.csv https://azureailabs.blob.core.windows.net/banking/banking_test.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['banking.csv', 'banking_test.csv', 'banking_train.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = '../datasets'\n",
    "filenames = ['banking_train.csv','banking_test.csv']\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "for filename in filenames:\n",
    "    downloadCommand = 'wget -O ''{0}/{1}'' ''https://azureailabs.blob.core.windows.net/banking/{1}'''.format(folder, filename)\n",
    "    print(downloadCommand)\n",
    "    os.system(downloadCommand)\n",
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32950 entries, 0 to 32949\n",
      "Data columns (total 21 columns):\n",
      "age               32950 non-null int64\n",
      "job               32950 non-null object\n",
      "marital           32950 non-null object\n",
      "education         32950 non-null object\n",
      "default           32950 non-null object\n",
      "housing           32950 non-null object\n",
      "loan              32950 non-null object\n",
      "contact           32950 non-null object\n",
      "month             32950 non-null object\n",
      "day_of_week       32950 non-null object\n",
      "duration          32950 non-null int64\n",
      "campaign          32950 non-null int64\n",
      "pdays             32950 non-null int64\n",
      "previous          32950 non-null int64\n",
      "poutcome          32950 non-null object\n",
      "emp_var_rate      32950 non-null float64\n",
      "cons_price_idx    32950 non-null float64\n",
      "cons_conf_idx     32950 non-null float64\n",
      "euribor3m         32950 non-null float64\n",
      "nr_employed       32950 non-null float64\n",
      "y                 32950 non-null int64\n",
      "dtypes: float64(5), int64(6), object(10)\n",
      "memory usage: 5.3+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>wed</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.964</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.958</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>admin.</td>\n",
       "      <td>divorced</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age            job   marital            education default housing loan  \\\n",
       "0   33     technician   married  professional.course      no     yes   no   \n",
       "1   31     unemployed   married    university.degree      no     yes   no   \n",
       "2   41  self-employed   married             basic.9y      no     yes   no   \n",
       "3   29         admin.    single    university.degree      no      no  yes   \n",
       "4   39         admin.  divorced          high.school      no     yes   no   \n",
       "\n",
       "     contact month day_of_week ...  campaign  pdays  previous     poutcome  \\\n",
       "0  telephone   jul         mon ...        17    999         0  nonexistent   \n",
       "1   cellular   aug         wed ...        11    999         0  nonexistent   \n",
       "2   cellular   jul         fri ...         2    999         0  nonexistent   \n",
       "3   cellular   jul         thu ...         2    999         0  nonexistent   \n",
       "4   cellular   jul         mon ...         5    999         0  nonexistent   \n",
       "\n",
       "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          1.4          93.918          -42.7      4.960       5228.1  0  \n",
       "1          1.4          93.444          -36.1      4.964       5228.1  0  \n",
       "2          1.4          93.918          -42.7      4.962       5228.1  0  \n",
       "3          1.4          93.918          -42.7      4.958       5228.1  1  \n",
       "4          1.4          93.918          -42.7      4.962       5228.1  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder = '../datasets'\n",
    "filename = 'banking_train.csv'\n",
    "pathname = os.path.join(folder, filename)\n",
    "df = pd.read_csv(pathname, delimiter=',')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset combines the information about the bank's customers with the results of previous campaigns and key economic indicators. It includes 41,188 records and 21 fields. The columns are a mix of numeric and categorical data types.\n",
    "\n",
    "The `y` column indicates whether the customer subscribed to a term deposit. This is our `target` variable or `label`. The goal of the model is to predict this column on new examples.\n",
    "\n",
    "Some information that exists in the historical dataset will not be available when planning a new campaign. \n",
    "\n",
    "Please refer to [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/bank+marketing) for more information. \n",
    "\n",
    "We will use the following features for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>month</th>\n",
       "      <th>campaign</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>technician</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>jul</td>\n",
       "      <td>17</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.960</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>aug</td>\n",
       "      <td>11</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.964</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>self-employed</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>married</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>jul</td>\n",
       "      <td>2</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>admin.</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>jul</td>\n",
       "      <td>2</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.958</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>admin.</td>\n",
       "      <td>high.school</td>\n",
       "      <td>divorced</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>jul</td>\n",
       "      <td>5</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.918</td>\n",
       "      <td>-42.7</td>\n",
       "      <td>4.962</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age            job            education   marital housing loan month  \\\n",
       "0   33     technician  professional.course   married     yes   no   jul   \n",
       "1   31     unemployed    university.degree   married     yes   no   aug   \n",
       "2   41  self-employed             basic.9y   married     yes   no   jul   \n",
       "3   29         admin.    university.degree    single      no  yes   jul   \n",
       "4   39         admin.          high.school  divorced     yes   no   jul   \n",
       "\n",
       "   campaign     poutcome  emp_var_rate  cons_price_idx  cons_conf_idx  \\\n",
       "0        17  nonexistent           1.4          93.918          -42.7   \n",
       "1        11  nonexistent           1.4          93.444          -36.1   \n",
       "2         2  nonexistent           1.4          93.918          -42.7   \n",
       "3         2  nonexistent           1.4          93.918          -42.7   \n",
       "4         5  nonexistent           1.4          93.918          -42.7   \n",
       "\n",
       "   euribor3m  nr_employed  y  \n",
       "0      4.960       5228.1  0  \n",
       "1      4.964       5228.1  0  \n",
       "2      4.962       5228.1  0  \n",
       "3      4.958       5228.1  1  \n",
       "4      4.962       5228.1  0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [\n",
    "                   # Demographic\n",
    "                   'age', \n",
    "                   'job', \n",
    "                   'education', \n",
    "                   'marital',  \n",
    "                   'housing', \n",
    "                   'loan', \n",
    "                   # Previous campaigns\n",
    "                   'month',\n",
    "                   'campaign',\n",
    "                   'poutcome',\n",
    "                   # Economic indicators\n",
    "                   'emp_var_rate',\n",
    "                   'cons_price_idx',\n",
    "                   'cons_conf_idx',\n",
    "                   'euribor3m',\n",
    "                   'nr_employed']\n",
    "\n",
    "df_train = df[feature_columns + ['y']]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-learn` estimators expect continuous input. Some of the features in the dataset are categorical and encoded as strings. We will use *dummy* encoding to convert categorical features to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, drop_first=True).astype(dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the class distribution in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f97082765f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(df_train.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training dataset is very imbalanced. We will need to address this when configuring training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "In this section of the lab you will train a binary classification model.\n",
    "\n",
    "You will first run training on a local workstation and use Azure Machine Learning Experiment to track training progress. In the following step, you will use Azure Machine Learning Compute to run  training on more powerful cloud compute resources.\n",
    "\n",
    "In the Azure Machine Learning service, you can track training artifacts (algorithm settings, performance metrics, logs, serialized models, etc.)  created during training iterations a.k.a *Runs* using Azure ML *Experiment*. To do that you must instrument your code with logging statements and trigger logging when you submit the *Run*. The following are two ways to trigger the run submission:\n",
    "\n",
    "- Start an interactive logging session in the specified *Experiment*. As you execute logging statements, any artifacts that are logged during the session are added to the run record in the experiment. We will use this approach when training the model on the local compute.\n",
    "\n",
    "- Add logging functions to your training script and trigger logging when submitting the script to run on a compute target. With this option, you can add monitoring code to be notified of completion or to get a visual widget to monitor. We will use this approach when training on a remote Azure Machine Learning Compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a local workstation\n",
    "#### Prepare training pipeline\n",
    "\n",
    "We are going to train a binomial *LogisticRegression* regression model. *LogisticRegression* exposes a number of tuneable hyperparameters. Argueable, the most important setting is the inverse of regularization strength **C** . For the sake of simplicity, we will focus on tuning this hyperparameter when training our model. We will use *GridSearchCV* to automate the hyperparameter tuning process. \n",
    "\n",
    "The business goal of our model is to identify customers with high propencity to buy. As such, we want to minimize the number of false negatives - customers who were wrongly identified as ones with low propencity to buy. We want the model with a high *recall*.\n",
    "\n",
    "Since the dataset is imbalanced we will set *class_weight* parameter to `balanced` to automatically adjust weights inversely proportional to class frequencies in in the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Create logistic regression estimater\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=300, class_weight='balanced')\n",
    "\n",
    "# Logistic regression requires feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a training pipeline\n",
    "pipeline = Pipeline(steps=[('scaler', scaler),\n",
    "                           ('lr', lr)])\n",
    "\n",
    "# Configure grid search\n",
    "param_grid = {'lr__C': [0.1, 0.5, 1, 2, 5]}\n",
    "clf = GridSearchCV(pipeline,\n",
    "                   param_grid, \n",
    "                   cv=5, \n",
    "                   scoring=['recall', 'accuracy'],\n",
    "                   refit = 'recall',\n",
    "                   return_train_score = False\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=300,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'lr__C': [0.1, 0.5, 1, 2, 5]}, pre_dispatch='2*n_jobs',\n",
       "       refit='recall', return_train_score=False,\n",
       "       scoring=['recall', 'accuracy'], verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.drop('y', axis=1)\n",
    "y = df_train.y\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Track the run in Azure Machine Learning Experiment\n",
    "\n",
    "Create an *Experiment* to track run records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "exp = Experiment(ws, \"propensity_to_buy_local_training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we used *GridSearchCV* to train multiple models with different setting for **C** we want to reflect this approach in a run record. One way to do that is to create a hierarcical run record structure mapping directly to our grid search training regime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing C: 0.1 and accuracy: 0.8260698027314113 and recall: 0.6298524017960675 in Run object\n",
      "Storing C: 0.5 and accuracy: 0.8271623672230652 and recall: 0.6287739945550839 in Run object\n",
      "Storing C: 1 and accuracy: 0.8274051593323217 and recall: 0.6287739945550839 in Run object\n",
      "Storing C: 2 and accuracy: 0.8274051593323217 and recall: 0.6282355548538359 in Run object\n",
      "Storing C: 5 and accuracy: 0.8274962063732929 and recall: 0.6282355548538359 in Run object\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.run import Run\n",
    "\n",
    "# Create a root run\n",
    "root_run = exp.start_logging()\n",
    "\n",
    "# Retrieve training results from GridSearchCV object and store them in child runs of the root run\n",
    "for C, accuracy, recall in zip(clf.cv_results_['params'], clf.cv_results_['mean_test_accuracy'], clf.cv_results_['mean_test_recall']):\n",
    "    run = root_run.child_run(\"Run with C set to {}\".format(C))\n",
    "    run.log(\"C\", C['lr__C'])\n",
    "    run.log(\"Accuracy\", accuracy)\n",
    "    run.log(\"Recall\", recall)\n",
    "    run.complete()\n",
    "    print(\"Storing C: {} and accuracy: {} and recall: {} in Run object\".format(C['lr__C'], accuracy, recall))\n",
    "    \n",
    "# Close the parent run in the experiment\n",
    "root_run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have captured history for various runs, you can review the runs. You can use the Azure Portal for this. You can also use the AML SDK to query the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': 'ebc70d13-89ba-4392-8b73-b4486635a189', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T03:29:44.721249Z', 'endTimeUtc': '2019-01-05T03:29:45.535132Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 5, 'Accuracy': 0.8274962063732929, 'Recall': 0.6282355548538359}\n",
      "------------------------------------------------------------\n",
      "{'runId': 'a148b966-434b-49ea-af57-aeb9bf7953a3', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T03:29:44.098351Z', 'endTimeUtc': '2019-01-05T03:29:44.459568Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 2, 'Accuracy': 0.8274051593323217, 'Recall': 0.6282355548538359}\n",
      "------------------------------------------------------------\n",
      "{'runId': '6ab431ef-a358-4fa3-bd8c-64bdf6bb2959', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T03:29:43.333529Z', 'endTimeUtc': '2019-01-05T03:29:43.69604Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 1, 'Accuracy': 0.8274051593323217, 'Recall': 0.6287739945550839}\n",
      "------------------------------------------------------------\n",
      "{'runId': '24b76ec0-b350-499b-bcf7-9ba05589ab11', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T03:29:41.780643Z', 'endTimeUtc': '2019-01-05T03:29:42.982868Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 0.5, 'Accuracy': 0.8271623672230652, 'Recall': 0.6287739945550839}\n",
      "------------------------------------------------------------\n",
      "{'runId': 'd48a0a19-e0ca-48a9-8ea0-bb4cbdfd4917', 'target': 'sdk', 'status': 'Completed', 'startTimeUtc': '2019-01-05T03:29:40.997318Z', 'endTimeUtc': '2019-01-05T03:29:41.40272Z', 'properties': {}, 'logFiles': {}}\n",
      "{'C': 0.1, 'Accuracy': 0.8260698027314113, 'Recall': 0.6298524017960675}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List all child runs\n",
    "runs = [r for r in root_run.get_children()]\n",
    "\n",
    "for run in runs:\n",
    "    print(run.get_details())\n",
    "    print(run.get_metrics())\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train remotely using Azure ML Compute\n",
    "\n",
    "Up until now, all of your training was executed locally on the same machine running Jupyter. Now you will execute the same logic targeting a remote Azure ML Compute, which you will provision from code.\n",
    "\n",
    "#### Provision Azure ML Compute Cluster\n",
    "\n",
    "We will provision an autoscale Azure ML Computer Cluster. In this lab we will only use a single node on the cluster. In the following labs we will multiple nodes on the cluster to run parallel model selection and hyper parameter tuning jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target, using this compute target instead of creating:  cpu-cluster\n"
     ]
    }
   ],
   "source": [
    "# Create an Azure ML Compute cluster\n",
    "\n",
    "# Create Azure ML cluster\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpu-cluster\"\n",
    "cluster_min_nodes = 1\n",
    "cluster_max_nodes = 3\n",
    "vm_size = \"STANDARD_DS11_V2\"\n",
    "\n",
    "if cluster_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[cluster_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found existing compute target, using this compute target instead of creating:  ' + cluster_name)\n",
    "    else:\n",
    "        print(\"Error: A compute target with name \",cluster_name,\" was found, but it is not of type AmlCompute.\")\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, \n",
    "                                                                min_nodes = cluster_min_nodes, \n",
    "                                                                max_nodes = cluster_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to AML DataStore\n",
    "With your cluster ready, you need to upload the training data to a location accessible by the cluster's nodes. \n",
    "\n",
    "*Datastore* is a storage abstraction over an Azure storage account. The datastore can use either an Azure blob container or an Azure file share as the back-end storage. Each workspace has a default datastore, and you can register additional datastores.\n",
    "\n",
    "We will upload the training data to the default Datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob jkamlworstoragebvcqonoz azureml-blobstore-77114569-d741-41ff-81b0-43cf36590b03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_3be9315b4d3b4d8ca11976f3d3d33f2e"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the dataset to the DataStore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "ds.upload(src_dir='../datasets', target_path='datasets', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a training script\n",
    "\n",
    "Next, you will need to create a training script that is similar to the code you have executed locally to train the model. The script will be executed remotely on Azure ML Compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from azureml.core.run import Run\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "# Retrieve command line arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str,  help='data folder mounting point')\n",
    "parser.add_argument('--filename', type=str,  help='training file name')\n",
    "parser.add_argument('--parameter-grid', type=float, nargs='+', help='regularization')\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_folder = os.path.join(args.data_folder, 'datasets')\n",
    "print('Loading data from: ', data_folder)\n",
    "data_csv_path = os.path.join(data_folder, args.filename)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_csv_path)\n",
    "\n",
    "# Preprocess the data\n",
    "feature_columns = [\n",
    "                   # Demographic\n",
    "                   'age', \n",
    "                   'job', \n",
    "                   'education', \n",
    "                   'marital',  \n",
    "                   'housing', \n",
    "                   'loan', \n",
    "                   # Previous campaigns\n",
    "                   'month',\n",
    "                   'campaign',\n",
    "                   'poutcome',\n",
    "                   # Economic indicators\n",
    "                   'emp_var_rate',\n",
    "                   'cons_price_idx',\n",
    "                   'cons_conf_idx',\n",
    "                   'euribor3m',\n",
    "                   'nr_employed']\n",
    "\n",
    "df = df[feature_columns + ['y']]\n",
    "df_train = pd.get_dummies(df, drop_first=True).astype(dtype='float')\n",
    "\n",
    "# Create logistic regression estimater\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=300, class_weight='balanced')\n",
    "\n",
    "# Logistic regression requires feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create a training pipeline\n",
    "pipeline = Pipeline(steps=[('scaler', scaler),\n",
    "                           ('lr', lr)])\n",
    "\n",
    "# Configure grid search\n",
    "param_grid = {'lr__C': args.parameter_grid}\n",
    "clf = GridSearchCV(pipeline,\n",
    "                   param_grid, \n",
    "                   cv=5, \n",
    "                   scoring=['recall', 'accuracy'],\n",
    "                   refit = 'recall',\n",
    "                   return_train_score = False\n",
    "                   )\n",
    "\n",
    "# Start training\n",
    "X = df_train.drop('y', axis=1)\n",
    "y = df_train.y\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Acquire the current run \n",
    "root_run = Run.get_context()\n",
    "\n",
    "# Retrieve training results from GridSearchCV object and store them in child runs of the root run\n",
    "for C, accuracy, recall in zip(clf.cv_results_['params'], clf.cv_results_['mean_test_accuracy'], clf.cv_results_['mean_test_recall']):\n",
    "    run = root_run.child_run(\"Run with C set to {}\".format(C))\n",
    "    run.log(\"C\", C['lr__C'])\n",
    "    run.log(\"Accuracy\", accuracy)\n",
    "    run.log(\"Recall\", recall)\n",
    "    run.complete()\n",
    "    print(\"Storing C: {} and accuracy: {} and recall: {} in Run object\".format(C['lr__C'], accuracy, recall))\n",
    "    \n",
    "\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "#joblib.dump(value=model, filename='outputs/model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure a remote job\n",
    "\n",
    "A run configuration is a set of instructions that defines how a script should be run in a specified compute target. The configuration includes a wide set of behavior definitions, such as whether to use an existing Python environment or to use a Conda environment that's built from a specification.\n",
    "\n",
    "There are different ways of specifing a run configuration. We will use a higher level *Estimator* abstraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator\n",
    "#############################\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--filename': 'banking_train.csv',\n",
    "    '--parameter-grid': [0.1, 0.5, 1, 2, 5]\n",
    "}\n",
    "\n",
    "est_config = Estimator(source_directory=script_folder,\n",
    "                       script_params=script_params,\n",
    "                       compute_target=compute_target,\n",
    "                       entry_script='train.py',\n",
    "                       conda_packages=['scikit-learn', 'pandas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the job\n",
    "\n",
    "Submit the job using the submit() method of the Experiment object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>classifier_training_amlcompute</td><td>classifier_training_amlcompute_1546659637396</td><td>azureml.scriptrun</td><td>Queued</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamlworkshop/providers/Microsoft.MachineLearningServices/workspaces/jkamlworkshop/experiments/classifier_training_amlcompute/runs/classifier_training_amlcompute_1546659637396\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: classifier_training_amlcompute,\n",
       "Id: classifier_training_amlcompute_1546659637396,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Queued)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Execute the estimator job\n",
    "#####################################\n",
    "\n",
    "# Create new experiment\n",
    "from azureml.core import Experiment\n",
    "experiment_name = \"classifier_training_amlcompute\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "run = exp.submit(config=est_config)\n",
    "run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor a remote run\n",
    "\n",
    "The call to start the run is asynchronous, it returns a **Preparing** or **Running** state as soon as the job is started.\n",
    "\n",
    "The first run takes longer. The subsequent runs, as long as the script dependencies don't change, are much faster.\n",
    "\n",
    "Here is what's happening while you wait:\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the estimator. In our case, this will be a base CPU image with the  `scikit-learn`, and `pandas` libraries. The image is uploaded to the workspace. This stage happens once for each Python environment since the container is cached for subsequent runs.  During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Running**: In this stage, the training script is sent to the remote Azure ML Compute, then the data in the default datastore is copied to the local storage on the cluster node , then the script is run. While the job is running, stdout and the ./logs directory are streamed to the run history. You can monitor the run's progress using these logs. \n",
    "\n",
    "- **Post-Processing**:  The ./outputs directory on the cluster node  is copied over to the run history in the workspace.\n",
    "\n",
    "You can check the progress of a running job in multiple ways. Below cells demonstrate how to use a Jupyter widget as well as a `wait_for_completion` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8700edc009c44abeac5b8e91b331c6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: classifier_training_amlcompute_1546659637396\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Loading data from:  /mnt/batch/tasks/shared/LS_root/jobs/jkamlworkshop/azureml/classifier_training_amlcompute_1546659637396/mounts/workspaceblobstore/datasets\n",
      "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=300,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))]),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'lr__C': [0.1, 0.5, 1.0, 2.0, 5.0]},\n",
      "       pre_dispatch='2*n_jobs', refit='recall', return_train_score=False,\n",
      "       scoring=['recall', 'accuracy'], verbose=0)\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.10066962242126465 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: classifier_training_amlcompute_1546659637396\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'classifier_training_amlcompute_1546659637396',\n",
       " 'target': 'cpu-cluster',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2019-01-05T03:40:56.347839Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': '3a16c44c-1be4-4a67-886c-a53d6d93bdd5'},\n",
       " 'runDefinition': {'Script': 'train.py',\n",
       "  'Arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_workspaceblobstore',\n",
       "   '--filename',\n",
       "   'banking_train.csv',\n",
       "   '--parameter-grid',\n",
       "   '0.1',\n",
       "   '0.5',\n",
       "   '1',\n",
       "   '2',\n",
       "   '5'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'cpu-cluster',\n",
       "  'DataReferences': {'workspaceblobstore': {'DataStoreName': 'workspaceblobstore',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': None,\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults']},\n",
       "      'scikit-learn',\n",
       "      'pandas']},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.2.0',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://jkamlworstoragebvcqonoz.blob.core.windows.net/azureml/ExperimentRun/classifier_training_amlcompute_1546659637396/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=AgTtb5Ew0ckZhTDckb5c5SN8LUft3AyOG%2FFRzJsIn9A%3D&st=2019-01-05T03%3A31%3A09Z&se=2019-01-05T11%3A41%3A09Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://jkamlworstoragebvcqonoz.blob.core.windows.net/azureml/ExperimentRun/classifier_training_amlcompute_1546659637396/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=GzQb3pkaJqzWoG%2Fo1rrLE%2BffpEYMMyk7kXQaGyVilQU%3D&st=2019-01-05T03%3A31%3A09Z&se=2019-01-05T11%3A41%3A09Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://jkamlworstoragebvcqonoz.blob.core.windows.net/azureml/ExperimentRun/classifier_training_amlcompute_1546659637396/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=yVqzNbXrfN5u2t3x%2Bu539YX2EMOkhydsYGHh8CMBzyE%3D&st=2019-01-05T03%3A31%3A09Z&se=2019-01-05T11%3A41%3A09Z&sp=r'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poll for job status\n",
    "run.wait_for_completion(show_output=True)  # value of True will display a verbose, streaming log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "01 model training",
  "notebookId": 863281121960369
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
